{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzymonNowakowski/diffusions/blob/master/rr_compute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rr function\n",
        "\n",
        "### Author: Piotr Pokarowski (R code) and Szymon Nowakowski (Python port and tests)\n",
        "\n"
      ],
      "metadata": {
        "id": "jJ7L2sWgqJ6D"
      },
      "id": "jJ7L2sWgqJ6D"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "dtype=torch.float32\n",
        "torch.set_printoptions(precision=11, sci_mode=False)"
      ],
      "metadata": {
        "id": "1kIYHB1wfDJh"
      },
      "id": "1kIYHB1wfDJh",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# karras to time conversion"
      ],
      "metadata": {
        "id": "tCjnPWGaXcd3"
      },
      "id": "tCjnPWGaXcd3"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.special import ndtr\n",
        "\n",
        "\n",
        "def karras_to_descending_time_with_zero(num_steps, device=\"cpu\", dtype=torch.float64):\n",
        "  start = 80.0 ** (1.0 / 7.0)\n",
        "  end = 0.002 ** (1.0 / 7.0)\n",
        "  sigma_root = torch.linspace(start, end, num_steps, dtype=dtype, device=device)\n",
        "  sigma = sigma_root ** 7.0\n",
        "\n",
        "  # tt = 1.0 - pnorm(-log(sigma), 0.4, 1)  = pnorm(log(sigma), -0.4, 1.0) (R)\n",
        "  time_schedule = ndtr(torch.log(sigma) + 0.4)\n",
        "  zero = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "  time_schedule = torch.cat([time_schedule, zero], dim=0).to(dtype = dtype)\n",
        "  return time_schedule\n",
        "time_schedule = karras_to_descending_time_with_zero(32)\n",
        "print(time_schedule)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNfWr6m6e5Ir",
        "outputId": "e91dc4d0-4b15-4192-a093-a2a91303f1bd"
      },
      "id": "wNfWr6m6e5Ir",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.99999913232, 0.99999792435, 0.99999507932, 0.99998845412,\n",
            "        0.99997322360, 0.99993871897, 0.99986183402, 0.99969369983,\n",
            "        0.99933374140, 0.99858138433, 0.99705097864, 0.99403205436,\n",
            "        0.98828030905, 0.97774522504, 0.95929237795, 0.92857203611,\n",
            "        0.88030329152, 0.80930728213, 0.71248097572, 0.59139362160,\n",
            "        0.45435508474, 0.31616975998, 0.19430168471, 0.10237586174,\n",
            "        0.04464934451, 0.01544938750, 0.00402577941, 0.00074003172,\n",
            "        0.00008826190, 0.00000612113, 0.00000021308, 0.00000000304,\n",
            "        0.00000000000], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wartości z funkcji zmieniającej F-predykcję w velocity"
      ],
      "metadata": {
        "id": "2_CqICgGevq2"
      },
      "id": "2_CqICgGevq2"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "normal = torch.distributions.Normal(0., 1.)\n",
        "\n",
        "logr_normal = lambda t, sigma_data, P_mean=-0.4, P_std=1.0, clamp = 1e-9: (\n",
        "        torch.log(torch.as_tensor(sigma_data, device=t.device, dtype=t.dtype))\n",
        "        - P_mean\n",
        "        - P_std * normal.icdf(t.clamp(clamp, 1.0 - clamp))\n",
        ")\n",
        "\n",
        "dlogr_dt_normal = lambda t, P_std=1.0, clamp = 1e-9: - P_std / normal.log_prob(normal.icdf(t.clamp(clamp, 1.0 - clamp))).exp()\n",
        "logr = logr_normal(torch.tensor([0.99999913232, 0.99999792435, 0.99999507932, 0.99998845412,\n",
        "        0.99997322360, 0.99993871897, 0.99986183402, 0.99969369983,\n",
        "        0.99933374140, 0.99858138433, 0.99705097864, 0.99403205436,\n",
        "        0.98828030905, 0.97774522504, 0.95929237795, 0.92857203611,\n",
        "        0.88030329152, 0.80930728213, 0.71248097572, 0.59139362160,\n",
        "        0.45435508474, 0.31616975998, 0.19430168471, 0.10237586174,\n",
        "        0.04464934451, 0.01544938750, 0.00402577941, 0.00074003172,\n",
        "        0.00008826190, 0.00000612113, 0.00000021308, 0.00000000304],\n",
        "       dtype=torch.float64), 0.5)\n",
        "print(logr)\n",
        "print(dlogr_dt_normal(torch.tensor([0.99999913232, 0.99999792435, 0.99999507932, 0.99998845412,\n",
        "        0.99997322360, 0.99993871897, 0.99986183402, 0.99969369983,\n",
        "        0.99933374140, 0.99858138433, 0.99705097864, 0.99403205436,\n",
        "        0.98828030905, 0.97774522504, 0.95929237795, 0.92857203611,\n",
        "        0.88030329152, 0.80930728213, 0.71248097572, 0.59139362160,\n",
        "        0.45435508474, 0.31616975998, 0.19430168471, 0.10237586174,\n",
        "        0.04464934451, 0.01544938750, 0.00402577941, 0.00074003172,\n",
        "        0.00008826190, 0.00000612113, 0.00000021308, 0.00000000304],\n",
        "       dtype=torch.float64), 0.5))\n",
        "\n",
        "print(0.5/logr.exp())\n",
        "\n",
        "print(0.5/logr_normal(time_schedule, 0.5).exp())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sBfevtN97pe",
        "outputId": "78fab709-5c33-4f30-bbc3-465c8ef0aba4"
      },
      "id": "7sBfevtN97pe",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-5.0752, -4.8968, -4.7138, -4.5258, -4.3327, -4.1341, -3.9297, -3.7191,\n",
            "        -3.5020, -3.2780, -3.0465, -2.8072, -2.5593, -2.3024, -2.0357, -1.7584,\n",
            "        -1.4697, -1.1685, -0.8538, -0.5243, -0.1785,  0.1853,  0.5690,  0.9750,\n",
            "         1.4060,  1.8652,  2.3568,  2.8854,  3.4573,  4.0801,  4.7637,  5.5214],\n",
            "       dtype=torch.float64)\n",
            "tensor([-1.1581e+05, -5.0143e+04, -2.1956e+04, -9.7362e+03, -4.3799e+03,\n",
            "        -2.0026e+03, -9.3260e+02, -4.4338e+02, -2.1578e+02, -1.0782e+02,\n",
            "        -5.5500e+01, -2.9547e+01, -1.6340e+01, -9.4343e+00, -5.7202e+00,\n",
            "        -3.6666e+00, -2.5040e+00, -1.8384e+00, -1.4666e+00, -1.2872e+00,\n",
            "        -1.2616e+00, -1.4053e+00, -1.8175e+00, -2.8007e+00, -5.3083e+00,\n",
            "        -1.2872e+01, -4.1963e+01, -1.9587e+02, -1.4204e+03, -1.7825e+04,\n",
            "        -4.4768e+05, -2.7515e+07], dtype=torch.float64)\n",
            "tensor([8.0000e+01, 6.6931e+01, 5.5736e+01, 4.6186e+01, 3.8075e+01, 3.1216e+01,\n",
            "        2.5445e+01, 2.0614e+01, 1.6591e+01, 1.3261e+01, 1.0521e+01, 8.2816e+00,\n",
            "        6.4637e+00, 4.9991e+00, 3.8287e+00, 2.9015e+00, 2.1739e+00, 1.6086e+00,\n",
            "        1.1743e+00, 8.4462e-01, 5.9770e-01, 4.1543e-01, 2.8304e-01, 1.8860e-01,\n",
            "        1.2257e-01, 7.7431e-02, 4.7364e-02, 2.7916e-02, 1.5757e-02, 8.4530e-03,\n",
            "        4.2668e-03, 2.0001e-03], dtype=torch.float64)\n",
            "tensor([8.0000e+01, 6.6931e+01, 5.5736e+01, 4.6186e+01, 3.8075e+01, 3.1216e+01,\n",
            "        2.5445e+01, 2.0614e+01, 1.6591e+01, 1.3261e+01, 1.0521e+01, 8.2816e+00,\n",
            "        6.4637e+00, 4.9991e+00, 3.8287e+00, 2.9015e+00, 2.1739e+00, 1.6086e+00,\n",
            "        1.1743e+00, 8.4462e-01, 5.9770e-01, 4.1543e-01, 2.8304e-01, 1.8860e-01,\n",
            "        1.2257e-01, 7.7431e-02, 4.7364e-02, 2.7916e-02, 1.5757e-02, 8.4530e-03,\n",
            "        4.2668e-03, 2.0000e-03], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `rr` function"
      ],
      "metadata": {
        "id": "bb4PYoO8g5sH"
      },
      "id": "bb4PYoO8g5sH"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "noise = torch.tensor([0.0000000], dtype=dtype, device=\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "def rr(num_steps: int, res_dtype: torch.dtype, device: torch.device):\n",
        "    \"\"\"\n",
        "    Implementation of the R logic in PyTorch.\n",
        "    Returns:\n",
        "        rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML\n",
        "    Each vector has length num_steps, sorted from largest to smallest,\n",
        "    with 0.0 appended at the end.\n",
        "    \"\"\"\n",
        "    num_steps = int(num_steps)\n",
        "    dtype = torch.float64\n",
        "\n",
        "    # s1 = seq(0.002^(1/7), 80^(1/7), len=TT)^7\n",
        "    start = 80.0 ** (1.0 / 7.0)\n",
        "    end = 0.002 ** (1.0 / 7.0)\n",
        "    s1_root = torch.linspace(start, end, num_steps, dtype=dtype, device=device)\n",
        "    s1 = s1_root ** 7.0\n",
        "\n",
        "    # roO = 1/s1\n",
        "    ro0 = 1.0 / s1\n",
        "\n",
        "    # R:\n",
        "    #   roO[-TT] = all except the last one  -> ro0[:-1]\n",
        "    #   roO[-1]  = all except the first one -> ro0[1:]\n",
        "    ro0_head = ro0[1:]   # roO[-TT]\n",
        "    ro0_tail = ro0[:-1]  # roO[-1]\n",
        "\n",
        "    # gaO = (roO[-TT]/roO[-1])^2\n",
        "    ga0 = (ro0_head / ro0_tail) ** 2.0  # (ro_new / ro_old)^2\n",
        "\n",
        "    # fpred = sqrt(1+4/roO[-1]^2)\n",
        "    fpred = torch.sqrt(1.0 + 4.0 / (ro0_tail ** 2.0))\n",
        "\n",
        "    # fpred = fpred*max(sqrt((gaO-1)/2)/fpred) +1e-10\n",
        "    scale = torch.max(torch.sqrt((ga0 - 1.0) / 2.0) / fpred)\n",
        "    fpred = fpred * scale + 1e-10\n",
        "\n",
        "    # eta2 = (gaO-1)^2 / (fpred*sqrt(2*gaO) + sqrt(2*fpred^2+1-gaO))^2\n",
        "    numer = (ga0 - 1.0) ** 2.0\n",
        "    denom = fpred * torch.sqrt(2.0 * ga0) + torch.sqrt(2.0 * fpred ** 2.0 + 1.0 - ga0)\n",
        "    eta2 = numer / (denom ** 2.0)  # eta^2\n",
        "\n",
        "    # ga = 1/(1 - eta2)\n",
        "    ga = 1.0 / (1.0 - eta2)  # (ro_new / ro_old)^2\n",
        "\n",
        "    # rrFLOW = 1/sqrt(gaO)     # r_old / r_new\n",
        "    rrFLOW = 1.0 / torch.sqrt(ga0)\n",
        "\n",
        "    # rrMSE = 1/sqrt(ga*gaO)   # r_old / r_new\n",
        "    rrMSE = 1.0 / torch.sqrt(ga * ga0)\n",
        "\n",
        "    # rrML = 1/gaO             # r_old / r_new\n",
        "    rrML = 1.0 / ga0\n",
        "\n",
        "    # betaMSE = sqrt(eta2)/roO[-TT]\n",
        "    betaMSE = torch.sqrt(eta2) / ro0_head\n",
        "\n",
        "    # betaML = sqrt(1 - 1/gaO)/roO[-TT]\n",
        "    betaML = torch.sqrt(1.0 - 1.0 / ga0) / ro0_head\n",
        "\n",
        "    # FLOW: all zeros (same length as betaMSE/betaML before appending zero)\n",
        "    betaFLOW = torch.zeros_like(betaMSE)\n",
        "\n",
        "    # append 0.0 at the end so the vector has length num_steps\n",
        "    zero = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "    rrFLOW   = torch.cat([rrFLOW,   zero], dim=0).to(dtype = res_dtype)\n",
        "    rrMSE    = torch.cat([rrMSE,    zero], dim=0).to(dtype = res_dtype)\n",
        "    rrML     = torch.cat([rrML,     zero], dim=0).to(dtype = res_dtype)\n",
        "    betaFLOW = torch.cat([betaFLOW, zero], dim=0).to(dtype = res_dtype)\n",
        "    betaMSE  = torch.cat([betaMSE,  zero], dim=0).to(dtype = res_dtype)\n",
        "    betaML   = torch.cat([betaML,   zero], dim=0).to(dtype = res_dtype)\n",
        "\n",
        "    # --- ML to FLOW validity check\n",
        "    assert torch.allclose(rrFLOW ** 2, rrML, atol=1e-6), \"FLOW^2 to ML rr mismatch\"\n",
        "\n",
        "    return rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "of3PH8dgSPWL"
      },
      "id": "of3PH8dgSPWL",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `rr_time_schedule` function"
      ],
      "metadata": {
        "id": "XS9Y-JQ-XYDJ"
      },
      "id": "XS9Y-JQ-XYDJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def rr_time_schedule(num_steps: int, time_schedule, res_dtype: torch.dtype, device: torch.device):\n",
        "    \"\"\"\n",
        "    Implementation of the R logic in PyTorch.\n",
        "    Returns:\n",
        "        rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, sigmas\n",
        "    Each vector (but the last) has length num_steps, sorted from largest to smallest,\n",
        "    with 0.0 appended at the end.\n",
        "\n",
        "    sigmas are length num_step+1\n",
        "\n",
        "    input time runs from 0 to 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    num_steps = int(num_steps)\n",
        "    dtype = torch.float64\n",
        "\n",
        "    # check length of time_schedule and num_steps\n",
        "    if time_schedule is not None and len(time_schedule) != num_steps:\n",
        "        raise ValueError(\n",
        "            f\"Expected time_schedule of length {num_steps}, \"\n",
        "            f\"got {len(time_schedule)}.\"\n",
        "        )\n",
        "\n",
        "    time_inferred = False\n",
        "\n",
        "    if time_schedule is None:\n",
        "          # s1 = seq(0.002^(1/7), 80^(1/7), len=TT)^7\n",
        "      start = 80.0 ** (1.0 / 7.0)\n",
        "      end = 0.002 ** (1.0 / 7.0)\n",
        "      sigma_root = torch.linspace(start, end, num_steps, dtype=dtype, device=device)\n",
        "      sigma = sigma_root ** 7.0\n",
        "\n",
        "      # tt = pnorm(-log(sigma), 0.4, 1)   (R)\n",
        "      normal_dist = torch.distributions.Normal(loc=torch.tensor(0.4, dtype=dtype, device=device),\n",
        "                                                 scale=torch.tensor(1.0, dtype=dtype, device=device))\n",
        "      time_schedule = normal_dist.cdf(-torch.log(sigma))\n",
        "      print(\"Inferred time:\",1-time_schedule)\n",
        "      time_inferred = True\n",
        "\n",
        "    time_schedule = time_schedule.to(dtype=dtype, device=device)  #conversion to common type and device for all paths\n",
        "\n",
        "    normal_dist_back = torch.distributions.Normal(loc=torch.tensor(0.4, dtype=dtype, device=device),\n",
        "                                                  scale=torch.tensor(1.0, dtype=dtype, device=device))\n",
        "    s1 = torch.exp(-normal_dist_back.icdf(time_schedule))  # sigma from time\n",
        "\n",
        "    if time_inferred:\n",
        "      assert torch.allclose(sigma, s1, atol=1e-6), \"sigma -> time -> sigma mismatch\"\n",
        "\n",
        "\n",
        "    # roO = 1/s1\n",
        "    ro0 = 1.0 / s1\n",
        "\n",
        "    # R:\n",
        "    #   roO[-TT] = all except the last one  -> ro0[:-1]\n",
        "    #   roO[-1]  = all except the first one -> ro0[1:]\n",
        "    ro0_head = ro0[1:]   # roO[-TT]\n",
        "    ro0_tail = ro0[:-1]  # roO[-1]\n",
        "\n",
        "    # gaO = (roO[-TT]/roO[-1])^2\n",
        "    ga0 = (ro0_head / ro0_tail) ** 2.0  # (ro_new / ro_old)^2\n",
        "\n",
        "    # fpred = sqrt(1+4/roO[-1]^2)\n",
        "    fpred = torch.sqrt(1.0 + 4.0 / (ro0_tail ** 2.0))\n",
        "\n",
        "    # fpred = fpred*max(sqrt((gaO-1)/2)/fpred) +1e-10\n",
        "    scale = torch.max(torch.sqrt((ga0 - 1.0) / 2.0) / fpred)\n",
        "    fpred = fpred * scale + 1e-10\n",
        "\n",
        "    # eta2 = (gaO-1)^2 / (fpred*sqrt(2*gaO) + sqrt(2*fpred^2+1-gaO))^2\n",
        "    numer = (ga0 - 1.0) ** 2.0\n",
        "    denom = fpred * torch.sqrt(2.0 * ga0) + torch.sqrt(2.0 * fpred ** 2.0 + 1.0 - ga0)\n",
        "    eta2 = numer / (denom ** 2.0)  # eta^2\n",
        "\n",
        "    # ga = 1/(1 - eta2)\n",
        "    ga = 1.0 / (1.0 - eta2)  # (ro_new / ro_old)^2\n",
        "\n",
        "    # rrFLOW = 1/sqrt(gaO)     # r_old / r_new\n",
        "    rrFLOW = 1.0 / torch.sqrt(ga0)\n",
        "\n",
        "    # rrMSE = 1/sqrt(ga*gaO)   # r_old / r_new\n",
        "    rrMSE = 1.0 / torch.sqrt(ga * ga0)\n",
        "\n",
        "    # rrML = 1/gaO             # r_old / r_new\n",
        "    rrML = 1.0 / ga0\n",
        "\n",
        "    # betaMSE = sqrt(eta2)/roO[-TT]\n",
        "    betaMSE = torch.sqrt(eta2) / ro0_head\n",
        "\n",
        "    # betaML = sqrt(1 - 1/gaO)/roO[-TT]\n",
        "    betaML = torch.sqrt(1.0 - 1.0 / ga0) / ro0_head\n",
        "\n",
        "    # FLOW: all zeros (same length as betaMSE/betaML before appending zero)\n",
        "    betaFLOW = torch.zeros_like(betaMSE)\n",
        "\n",
        "    # append 0.0 at the end so the vector has length num_steps\n",
        "    zero = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "    s1       = torch.cat([s1,   zero], dim=0).to(dtype = res_dtype)\n",
        "    rrFLOW   = torch.cat([rrFLOW,   zero], dim=0).to(dtype = res_dtype)\n",
        "    rrMSE    = torch.cat([rrMSE,    zero], dim=0).to(dtype = res_dtype)\n",
        "    rrML     = torch.cat([rrML,     zero], dim=0).to(dtype = res_dtype)\n",
        "    betaFLOW = torch.cat([betaFLOW, zero], dim=0).to(dtype = res_dtype)\n",
        "    betaMSE  = torch.cat([betaMSE,  zero], dim=0).to(dtype = res_dtype)\n",
        "    betaML   = torch.cat([betaML,   zero], dim=0).to(dtype = res_dtype)\n",
        "\n",
        "    # --- ML to FLOW validity check\n",
        "    assert torch.allclose(rrFLOW ** 2, rrML, atol=1e-6), \"FLOW^2 to ML rr mismatch\"\n",
        "\n",
        "    return rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, s1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QO6xJQSdMKwq"
      },
      "id": "QO6xJQSdMKwq",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSERTS FOR KARRAS SIGMA SCHEDULE COMPUTE"
      ],
      "metadata": {
        "id": "pVnPHteXXSdI"
      },
      "id": "pVnPHteXXSdI"
    },
    {
      "cell_type": "code",
      "source": [
        "r_vals_FLOW = torch.tensor([  #rrFLOW by Pokar - sigma ratios\n",
        "        0.8366359, 0.8327429, 0.8286604, 0.8243743, 0.8198691,\n",
        "        0.8151275, 0.8101306, 0.8048572, 0.7992839, 0.7933844,\n",
        "        0.7871296, 0.7804864, 0.7734178, 0.7658819, 0.7578312,\n",
        "        0.7492115, 0.7399610, 0.7300084, 0.7192719, 0.7076561,\n",
        "        0.6950504, 0.6813246, 0.6663258, 0.6498723, 0.6317477,\n",
        "        0.6116921, 0.5893917, 0.5644651, 0.5364472, 0.5047683,\n",
        "        0.4687320, 0.0000000\n",
        "    ], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_FLOW = torch.tensor([\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000,\n",
        "  0.0000000, 0.0000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_MSE = torch.tensor([  #rrMSE by Pokar\n",
        "  0.8366357, 0.8327426, 0.8286600, 0.8243737, 0.8198681,\n",
        "  0.8151260, 0.8101281, 0.8048533, 0.7992774, 0.7933737,\n",
        "  0.7871113, 0.7804548, 0.7733622, 0.7657820, 0.7576482,\n",
        "  0.7488696, 0.7393110, 0.7287571, 0.7168593, 0.7030898,\n",
        "  0.6868220, 0.6676873, 0.6459559, 0.6222139, 0.5965456,\n",
        "  0.5682467, 0.5359994, 0.4978241, 0.4503007, 0.3852130,\n",
        "  0.2197134, 0.0000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_MSE = torch.tensor([\n",
        "  0.043344183, 0.044376738, 0.045459380, 0.046595754, 0.047789821,\n",
        "  0.049045871, 0.050368504, 0.051762576, 0.053233054, 0.054784720,\n",
        "  0.056421549, 0.058145500, 0.059954137, 0.061835954, 0.063761203,\n",
        "  0.065663974, 0.067407924, 0.068724701, 0.069120044, 0.067790560,\n",
        "  0.063734535, 0.056347248, 0.046276620, 0.035376323, 0.025486142,\n",
        "  0.017531299, 0.011610107, 0.007427481, 0.004594182, 0.002757327,\n",
        "  0.001766672, 0.000000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_MSE_63 = torch.tensor([  # rrMSE by Pokar\n",
        "  0.915197, 0.9141584, 0.9130933, 0.9120015, 0.9108819,\n",
        "  0.9097335, 0.9085551, 0.9073455, 0.9061035, 0.9048278,\n",
        "\n",
        "  0.9035169, 0.9021693, 0.9007836, 0.8993580, 0.8978907,\n",
        "  0.8963800, 0.8948237, 0.8932197, 0.8915658, 0.8898594,\n",
        "\n",
        "  0.8880979, 0.8862783, 0.8843976, 0.8824521, 0.8804380,\n",
        "  0.8783509, 0.8761857, 0.8739365, 0.8715964, 0.8691570,\n",
        "\n",
        "  0.8666081, 0.8639367, 0.8611263, 0.8581559, 0.8549980,\n",
        "  0.8516176, 0.8479704, 0.8440028, 0.8396537, 0.8348607,\n",
        "\n",
        "  0.8295707, 0.8237538, 0.8174154, 0.8105968, 0.8033628,\n",
        "  0.7957759, 0.7878728, 0.7796501, 0.7710623, 0.7620285,\n",
        "\n",
        "  0.7524396, 0.7421621, 0.7310375, 0.7188746, 0.7054347,\n",
        "  0.6904060, 0.6733564, 0.6536437, 0.6302156, 0.6010721,\n",
        "\n",
        "  0.5611755, 0.4592289, 0.0000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_MSE_63 = torch.tensor([\n",
        "  0.039073243, 0.039551953, 0.040042504, 0.040545336, 0.041060907,\n",
        "  0.041589700, 0.042132218, 0.042688988, 0.043260559, 0.043847507,\n",
        "\n",
        "  0.044450430, 0.045069949, 0.045706711, 0.046361379, 0.047034633,\n",
        "  0.047727167, 0.048439675, 0.049172840, 0.049927320, 0.050703719,\n",
        "\n",
        "  0.051502552, 0.052324197, 0.053168821, 0.054036279, 0.054925978,\n",
        "  0.055836674, 0.056766194, 0.057711046, 0.058665866, 0.059622650,\n",
        "\n",
        "  0.060569693, 0.061490129, 0.062359987, 0.063145664, 0.063800839,\n",
        "  0.064263066, 0.064450726, 0.064261832, 0.063577149, 0.062270922,\n",
        "\n",
        "  0.060231804, 0.057392975, 0.053763558, 0.049447122, 0.044634229,\n",
        "  0.039567833, 0.034495387, 0.029627320, 0.025114529, 0.021045563,\n",
        "\n",
        "  0.017456520, 0.014345626, 0.011687116, 0.009442081, 0.007565980,\n",
        "  0.006013398, 0.004740838, 0.003708284, 0.002880117, 0.002226155,\n",
        "\n",
        "  0.001725404, 0.001470735, 0.000000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_ML = torch.tensor([  #rrML by Pokar - sigma ratios squared\n",
        "  0.6999597, 0.6934608, 0.6866781, 0.6795930, 0.6721853,\n",
        "  0.6644328, 0.6563115, 0.6477951, 0.6388547, 0.6294589,\n",
        "  0.6195730, 0.6091590, 0.5981751, 0.5865751, 0.5743081,\n",
        "  0.5613179, 0.5475422, 0.5329123, 0.5173520, 0.5007772,\n",
        "  0.4830950, 0.4642033, 0.4439901, 0.4223341, 0.3991052,\n",
        "  0.3741673, 0.3473825, 0.3186209, 0.2877756, 0.2547910,\n",
        "  0.2197097, 0.0000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_ML = torch.tensor([\n",
        "  36.662013635, 30.858902915, 25.852908864, 21.552093680, 17.872989770,\n",
        "  14.740026867, 12.084983057, 9.846459379, 7.969377645, 6.404501137,\n",
        "  5.107977807, 4.040905633, 3.168919747, 2.461800968, 1.893105349,\n",
        "  1.439814351, 1.082005249, 0.802541356, 0.586781653, 0.422309410,\n",
        "  0.298679353, 0.207182933, 0.140631255, 0.093155182, 0.060022151,\n",
        "  0.037469196, 0.022551663, 0.013007109, 0.007133814, 0.003683362,\n",
        "  0.001766681, 0.000000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_ML_63 = torch.tensor([  # rrML by Pokar\n",
        "  0.8375871, 0.8356859, 0.8337398, 0.8317472, 0.8297064,\n",
        "  0.8276157, 0.8254732, 0.8232769, 0.8210249, 0.8187149,\n",
        "\n",
        "  0.8163448, 0.8139120, 0.8114143, 0.8088489, 0.8062130,\n",
        "  0.8035037, 0.8007179, 0.7978524, 0.7949037, 0.7918681,\n",
        "\n",
        "  0.7887418, 0.7855207, 0.7822003, 0.7787762, 0.7752433,\n",
        "  0.7715965, 0.7678302, 0.7639385, 0.7599150, 0.7557531,\n",
        "\n",
        "  0.7514454, 0.7469843, 0.7423615, 0.7375682, 0.7325948,\n",
        "  0.7274312, 0.7220663, 0.7164883, 0.7106844, 0.7046408,\n",
        "\n",
        "  0.6983426, 0.6917737, 0.6849164, 0.6777517, 0.6702590,\n",
        "  0.6624157, 0.6541970, 0.6455762, 0.6365238, 0.6270075,\n",
        "\n",
        "  0.6169919, 0.6064379, 0.5953028, 0.5835392, 0.5710949,\n",
        "  0.5579123, 0.5439274, 0.5290698, 0.5132614, 0.4964158,\n",
        "\n",
        "  0.4784378, 0.4592230, 0.0000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_ML_63 = torch.tensor([\n",
        "  29.506336512, 27.130884030, 24.919304383, 22.862229095, 20.950711687,\n",
        "  19.176213924, 17.530592329, 16.006084966, 14.595298502, 13.291195523,\n",
        "\n",
        "  12.087082127, 10.976595773, 9.953693395, 9.012639773, 8.147996166,\n",
        "  7.354609196, 6.627599987, 5.962353561, 5.354508476, 4.799946715,\n",
        "\n",
        "  4.294783827, 3.835359299, 3.418227182, 3.040146953, 2.698074608,\n",
        "  2.389154001, 2.110708411, 1.860232339, 1.635383539, 1.433975272,\n",
        "\n",
        "  1.253968783, 1.093466009, 0.950702499, 0.824040553, 0.711962584,\n",
        "  0.613064683, 0.526050405, 0.449724754, 0.382988384, 0.324831999,\n",
        "\n",
        "  0.274330953, 0.230640051, 0.192988549, 0.160675344, 0.133064358,\n",
        "  0.109580108, 0.089703466, 0.072967598, 0.058954091, 0.047289246,\n",
        "\n",
        "  0.037640559, 0.029713366, 0.023247663, 0.018015084, 0.013816053,\n",
        "  0.010477088, 0.007848268, 0.005800850, 0.004225037, 0.003027900,\n",
        "\n",
        "  0.002131431, 0.001470751, 0.000000000\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "# --- execute rr function ---\n",
        "rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML = rr(32, dtype, noise.device)\n",
        "\n",
        "# --- comparison FLOW ---\n",
        "assert torch.allclose(rrFLOW, r_vals_FLOW, atol=1e-6), \"FLOW rr mismatch\"\n",
        "assert torch.allclose(betaFLOW, betas_diffusion_FLOW, atol=1e-6), \"FLOW beta mismatch\"\n",
        "\n",
        "# --- comparison MSE ---\n",
        "assert torch.allclose(rrMSE, r_vals_MSE, atol=1e-6), \"MSE rr mismatch\"\n",
        "assert torch.allclose(betaMSE, betas_diffusion_MSE, atol=1e-6), \"MSE beta mismatch\"\n",
        "\n",
        "# --- comparison ML ---\n",
        "assert torch.allclose(rrML, r_vals_ML, atol=1e-6), \"ML rr mismatch\"\n",
        "assert torch.allclose(betaML, betas_diffusion_ML, atol=1e-6), \"ML beta mismatch\"\n",
        "\n",
        "# --- execute rr function ---\n",
        "rrFLOW_63, rrMSE_63, rrML_63, betaFLOW_63, betaMSE_63, betaML_63 = rr(63, dtype, noise.device)\n",
        "\n",
        "# --- MSE ---\n",
        "assert torch.allclose(rrMSE_63, r_vals_MSE_63, atol=1e-6), \"MSE-63 rr mismatch\"\n",
        "assert torch.allclose(betaMSE_63, betas_diffusion_MSE_63, atol=1e-6), \"MSE-63 beta mismatch\"\n",
        "\n",
        "# --- ML ---\n",
        "assert torch.allclose(rrML_63, r_vals_ML_63, atol=1e-6), \"ML-63 rr mismatch\"\n",
        "assert torch.allclose(betaML_63, betas_diffusion_ML_63, atol=1e-6), \"ML-63 beta mismatch\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FeqT2bQRW_je"
      },
      "id": "FeqT2bQRW_je",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSERTS FOR TIME_SCHEDULE COMPUTE"
      ],
      "metadata": {
        "id": "7pK9jJlmXMkc"
      },
      "id": "7pK9jJlmXMkc"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- execute rr function ---\n",
        "rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, sigmas = rr_time_schedule(32, None, dtype, noise.device)\n",
        "\n",
        "# --- comparison FLOW ---\n",
        "assert torch.allclose(rrFLOW, r_vals_FLOW, atol=1e-6), \"FLOW rr mismatch\"\n",
        "assert torch.allclose(betaFLOW, betas_diffusion_FLOW, atol=1e-6), \"FLOW beta mismatch\"\n",
        "\n",
        "# --- comparison MSE ---\n",
        "assert torch.allclose(rrMSE, r_vals_MSE, atol=1e-6), \"MSE rr mismatch\"\n",
        "assert torch.allclose(betaMSE, betas_diffusion_MSE, atol=1e-6), \"MSE beta mismatch\"\n",
        "\n",
        "# --- comparison ML ---\n",
        "assert torch.allclose(rrML, r_vals_ML, atol=1e-6), \"ML rr mismatch\"\n",
        "assert torch.allclose(betaML, betas_diffusion_ML, atol=1e-6), \"ML beta mismatch\"\n",
        "\n",
        "print(sigmas)\n",
        "\n",
        "# --- execute rr function ---\n",
        "rrFLOW_63, rrMSE_63, rrML_63, betaFLOW_63, betaMSE_63, betaML_63, sigmas = rr_time_schedule(63, None, dtype, noise.device)\n",
        "\n",
        "# --- MSE ---\n",
        "assert torch.allclose(rrMSE_63, r_vals_MSE_63, atol=1e-6), \"MSE-63 rr mismatch\"\n",
        "assert torch.allclose(betaMSE_63, betas_diffusion_MSE_63, atol=1e-6), \"MSE-63 beta mismatch\"\n",
        "\n",
        "# --- ML ---\n",
        "assert torch.allclose(rrML_63, r_vals_ML_63, atol=1e-6), \"ML-63 rr mismatch\"\n",
        "assert torch.allclose(betaML_63, betas_diffusion_ML_63, atol=1e-6), \"ML-63 beta mismatch\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lh3jU4qPPF9",
        "outputId": "30e73cb0-5a70-4dd7-df69-405bb8d442de"
      },
      "id": "_Lh3jU4qPPF9",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred time: tensor([0.99999913232, 0.99999792435, 0.99999507932, 0.99998845412,\n",
            "        0.99997322360, 0.99993871897, 0.99986183402, 0.99969369983,\n",
            "        0.99933374140, 0.99858138433, 0.99705097864, 0.99403205436,\n",
            "        0.98828030905, 0.97774522504, 0.95929237795, 0.92857203611,\n",
            "        0.88030329152, 0.80930728213, 0.71248097572, 0.59139362160,\n",
            "        0.45435508474, 0.31616975998, 0.19430168471, 0.10237586174,\n",
            "        0.04464934451, 0.01544938750, 0.00402577941, 0.00074003172,\n",
            "        0.00008826190, 0.00000612113, 0.00000021308, 0.00000000304],\n",
            "       dtype=torch.float64)\n",
            "tensor([80.00000000000, 66.93087005615, 55.73620986938, 46.18638992310,\n",
            "        38.07487487793, 31.21641349792, 25.44535636902, 20.61406135559,\n",
            "        16.59137535095, 13.26121807098, 10.52124404907,  8.28158187866,\n",
            "         6.46366214752,  4.99911117554,  3.82872891426,  2.90153026581,\n",
            "         2.17385983467,  1.60857141018,  1.17427062988,  0.84461987019,\n",
            "         0.59770041704,  0.41543191671,  0.28304401040,  0.18859951198,\n",
            "         0.12256561220,  0.07743054628,  0.04736365750,  0.02791574597,\n",
            "         0.01575746574,  0.00845304783,  0.00426683063,  0.00200000009,\n",
            "         0.00000000000])\n",
            "Inferred time: tensor([0.99999913232, 0.99999865657, 0.99999792435, 0.99999680028,\n",
            "        0.99999507932, 0.99999245219, 0.99998845412, 0.99998238978,\n",
            "        0.99997322360, 0.99995942085, 0.99993871897, 0.99990780109,\n",
            "        0.99986183402, 0.99979382043, 0.99969369983, 0.99954711515,\n",
            "        0.99933374140, 0.99902505258, 0.99858138433, 0.99794813854,\n",
            "        0.99705097864, 0.99578989127, 0.99403205436, 0.99160356984,\n",
            "        0.98828030905, 0.98377839561, 0.97774522504, 0.96975238616,\n",
            "        0.95929237795, 0.94578154132, 0.92857203611, 0.90697582705,\n",
            "        0.88030329152, 0.84791800226, 0.80930728213, 0.76416520505,\n",
            "        0.71248097572, 0.65462153184, 0.59139362160, 0.52406870011,\n",
            "        0.45435508474, 0.38430699946, 0.31616975998, 0.25217346751,\n",
            "        0.19430168471, 0.14407280284, 0.10237586174, 0.06939622806,\n",
            "        0.04464934451, 0.02711621184, 0.01544938750, 0.00820148722,\n",
            "        0.00402577941, 0.00181152810, 0.00074003172, 0.00027143054,\n",
            "        0.00008826190, 0.00002507672, 0.00000612113, 0.00000125871,\n",
            "        0.00000021308, 0.00000002890, 0.00000000304], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSERTS FOR THE NEW VECTOR IN NEW TIME FROM POKAR"
      ],
      "metadata": {
        "id": "iWGmBBZPXj6k"
      },
      "id": "iWGmBBZPXj6k"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- R reference vectors (with trailing 0 added) ---\n",
        "\n",
        "r_vals_FLOW = torch.tensor([\n",
        "    0.7345387, 0.7348875, 0.7349970, 0.7349791, 0.7349975, 0.7349982,\n",
        "    0.7349997, 0.7349998, 0.7349999, 0.7350000, 0.7350000, 0.7350000,\n",
        "    0.7350000, 0.7350000, 0.7350000, 0.7350000, 0.7350000, 0.7350000,\n",
        "    0.7350000, 0.7350000, 0.7350000, 0.7350000, 0.7350000, 0.7349999,\n",
        "    0.7349998, 0.7350000, 0.7350000, 0.7350009, 0.7350127, 0.7349762,\n",
        "    0.7348165, 0.0\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_MSE = torch.tensor([\n",
        "    0.7345372, 0.7348848, 0.7349920, 0.7349699, 0.7349803, 0.7349664,\n",
        "    0.7349409, 0.7348910, 0.7347987, 0.7346281, 0.7343136, 0.7337365,\n",
        "    0.7326850, 0.7307932, 0.7274657, 0.7218307, 0.7128428, 0.6996880,\n",
        "    0.6824207, 0.6623045, 0.6413822, 0.6216069, 0.6042523, 0.5898395,\n",
        "    0.5783554, 0.5695043, 0.5628810, 0.5580995, 0.5550202, 0.5518533,\n",
        "    0.5399612, 0.0\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "r_vals_ML = torch.tensor([\n",
        "    0.5395471, 0.5400596, 0.5402206, 0.5401943, 0.5402213, 0.5402223,\n",
        "    0.5402245, 0.5402247, 0.5402249, 0.5402250, 0.5402249, 0.5402249,\n",
        "    0.5402250, 0.5402250, 0.5402250, 0.5402250, 0.5402250, 0.5402250,\n",
        "    0.5402250, 0.5402250, 0.5402250, 0.5402250, 0.5402250, 0.5402248,\n",
        "    0.5402247, 0.5402250, 0.5402249, 0.5402263, 0.5402436, 0.5401900,\n",
        "    0.5399553, 0.0\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_MSE = torch.tensor([\n",
        "    0.143822161, 0.143632291, 0.143571233, 0.143577768, 0.143562001, 0.143550840,\n",
        "    0.143530086, 0.143493101, 0.143424819, 0.143298828, 0.143066769, 0.142640844,\n",
        "    0.141864697, 0.140468443, 0.138012435, 0.133852989, 0.127217927, 0.117505125,\n",
        "    0.104751697, 0.089885799, 0.074409376, 0.059756709, 0.046859975, 0.036094978,\n",
        "    0.027439548, 0.020660068, 0.015446663, 0.011488729, 0.008507573, 0.006299481,\n",
        "    0.004753566, 0.0\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_ML = torch.tensor([\n",
        "    48.842260047, 35.873584716, 26.362361470, 19.376339474, 14.241143273, 10.467202884,\n",
        "    7.693372483, 5.654626059, 4.156149044, 3.054769256, 2.245255411, 1.650262638,\n",
        "    1.212942967, 0.891513082, 0.655262111, 0.481617644, 0.353988964, 0.260181889,\n",
        "    0.191233685, 0.140556758, 0.103309216, 0.075932271, 0.055810220, 0.041020514,\n",
        "    0.030150073, 0.022160298, 0.016287819, 0.011971544, 0.008799071, 0.006467485,\n",
        "    0.004753627, 0.0\n",
        "], dtype=dtype, device=noise.device)\n",
        "\n",
        "betas_diffusion_FLOW = torch.zeros_like(betas_diffusion_MSE)  # FLOW always zero\n",
        "\n",
        "\n",
        "const_FLOW = torch.tensor([0.00000031, 0.00000146, 0.00000626, 0.00002449, 0.00008753,\n",
        "      0.00028591, 0.00085415, 0.00233565, 0.00585138, 0.01344545,\n",
        "      0.02837619, 0.05509628, 0.09862199, 0.16315867, 0.25025935,\n",
        "      0.35726125, 0.47691245, 0.59869879, 0.71153182, 0.80668639,\n",
        "      0.87972935, 0.93076593, 0.96322515, 0.98201601, 0.99191762,\n",
        "      0.99666674, 0.99874006, 0.99956394, 0.99986193, 0.99996003,\n",
        "      0.99998943, 0.99999745], dtype=dtype, device=noise.device)\n",
        "\n",
        "# --- execute rr function ---\n",
        "rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, sigmas = rr_time_schedule(\n",
        "    32, const_FLOW,\n",
        "    dtype,\n",
        "    noise.device\n",
        ")\n",
        "\n",
        "print(\"SIGMAS =\", sigmas)\n",
        "print(\"rrFLOW =\", rrFLOW)\n",
        "print(\"rrMSE  =\", rrMSE)\n",
        "print(\"rrML   =\", rrML)\n",
        "\n",
        "print(\"betaFLOW =\", betaFLOW)\n",
        "print(\"betaMSE  =\", betaMSE)\n",
        "print(\"betaML   =\", betaML)\n",
        "\n",
        "print(\"\\n\\nUWAGA! rrMSE - R-reference =\", rrMSE - r_vals_MSE)\n",
        "# --- comparison FLOW ---\n",
        "assert torch.allclose(rrFLOW, r_vals_FLOW, atol=0.0011), \"FLOW rr mismatch\"\n",
        "assert torch.allclose(betaFLOW, betas_diffusion_FLOW, atol=1e-6), \"FLOW beta mismatch\"\n",
        "\n",
        "# --- comparison MSE ---\n",
        "assert torch.allclose(rrMSE, r_vals_MSE, atol=0.03), \"MSE rr mismatch\"\n",
        "assert torch.allclose(betaMSE, betas_diffusion_MSE, atol=1e-3), \"MSE beta mismatch\"\n",
        "\n",
        "# --- comparison ML ---\n",
        "assert torch.allclose(rrML, r_vals_ML, atol=0.0017), \"ML rr mismatch\"\n",
        "assert torch.allclose(betaML, betas_diffusion_ML, atol=1e-5), \"ML beta mismatch\"\n"
      ],
      "metadata": {
        "id": "JzxeMhpbWt8m",
        "outputId": "c31fce89-cf66-49cf-a482-7288e3df4f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JzxeMhpbWt8m",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIGMAS = tensor([97.99151611328, 71.97856140137, 52.89614105225, 38.87850570679,\n",
            "        28.57489013672, 21.00247383118, 15.43677997589, 11.34602832794,\n",
            "         8.33932876587,  6.12940597534,  4.50511360168,  3.31125831604,\n",
            "         2.43377470970,  1.78882431984,  1.31478595734,  0.96636766195,\n",
            "         0.71028023958,  0.52205592394,  0.38371112943,  0.28202766180,\n",
            "         0.20729035139,  0.15235839784,  0.11198344827,  0.08230778575,\n",
            "         0.06049625948,  0.04446476698,  0.03268143535,  0.02402106859,\n",
            "         0.01765457727,  0.01297888160,  0.00953371730,  0.00701598777,\n",
            "         0.00000000000])\n",
            "rrFLOW = tensor([0.73453867435, 0.73488748074, 0.73499703407, 0.73497915268,\n",
            "        0.73499751091, 0.73499822617, 0.73499965668, 0.73499983549,\n",
            "        0.73499995470, 0.73500001431, 0.73499995470, 0.73499995470,\n",
            "        0.73500001431, 0.73500001431, 0.73499995470, 0.73500001431,\n",
            "        0.73500001431, 0.73500001431, 0.73499995470, 0.73500007391,\n",
            "        0.73499995470, 0.73500019312, 0.73499953747, 0.73500049114,\n",
            "        0.73500025272, 0.73499619961, 0.73500651121, 0.73496216536,\n",
            "        0.73515677452, 0.73455613852, 0.73591315746, 0.00000000000])\n",
            "rrMSE  = tensor([0.73453724384, 0.73488473892, 0.73499202728, 0.73496985435,\n",
            "        0.73498034477, 0.73496645689, 0.73494094610, 0.73489111662,\n",
            "        0.73479896784, 0.73462855816, 0.73431444168, 0.73373806477,\n",
            "        0.73268789053, 0.73079860210, 0.72747558355, 0.72184878588,\n",
            "        0.71287554502, 0.69974660873, 0.68252289295, 0.66247713566,\n",
            "        0.64166212082, 0.62204527855, 0.60491013527, 0.59080737829,\n",
            "        0.57972574234, 0.57134389877, 0.56545346975, 0.56065607071,\n",
            "        0.56115710735, 0.53957867622, 0.56936705112, 0.00000000000])\n",
            "rrML   = tensor([0.53954708576, 0.54005956650, 0.54022061825, 0.54019433260,\n",
            "        0.54022133350, 0.54022234678, 0.54022455215, 0.54022473097,\n",
            "        0.54022490978, 0.54022496939, 0.54022496939, 0.54022496939,\n",
            "        0.54022496939, 0.54022502899, 0.54022496939, 0.54022496939,\n",
            "        0.54022496939, 0.54022496939, 0.54022496939, 0.54022514820,\n",
            "        0.54022490978, 0.54022532701, 0.54022431374, 0.54022574425,\n",
            "        0.54022538662, 0.54021942616, 0.54023456573, 0.54016935825,\n",
            "        0.54045546055, 0.53957277536, 0.54156816006, 0.00000000000])\n",
            "betaFLOW = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "betaMSE  = tensor([0.14373373985, 0.14354398847, 0.14348295331, 0.14348949492,\n",
            "        0.14347372949, 0.14346255362, 0.14344179630, 0.14340481162,\n",
            "        0.14333650470, 0.14321048558, 0.14297835529, 0.14255230129,\n",
            "        0.14177595079, 0.14037927985, 0.13792259991, 0.13376201689,\n",
            "        0.12712520361, 0.11740995944, 0.10465361923, 0.08978460729,\n",
            "        0.07430559397, 0.05965079367, 0.04675332457, 0.03598764911,\n",
            "        0.02733356692, 0.02055915631, 0.01534625702, 0.01141529437,\n",
            "        0.00838468224, 0.00646900060, 0.00444509834, 0.00000000000])\n",
            "betaML   = tensor([48.84225845337, 35.87358474731, 26.36236190796, 19.37633895874,\n",
            "        14.24114322662, 10.46720314026,  7.69337272644,  5.65462589264,\n",
            "         4.15614891052,  3.05476927757,  2.24525547028,  1.65026259422,\n",
            "         1.21294295788,  0.89151304960,  0.65526211262,  0.48161765933,\n",
            "         0.35398897529,  0.26018187404,  0.19123369455,  0.14055675268,\n",
            "         0.10330922902,  0.07593227178,  0.05581024289,  0.04102049395,\n",
            "         0.03015008382,  0.02216034010,  0.01628772728,  0.01197171211,\n",
            "         0.00879834685,  0.00646908395,  0.00475035654,  0.00000000000])\n",
            "\n",
            "\n",
            "UWAGA! rrMSE - R-reference = tensor([ 0.00000005960, -0.00000005960,  0.00000000000, -0.00000005960,\n",
            "         0.00000005960,  0.00000005960,  0.00000005960,  0.00000011921,\n",
            "         0.00000023842,  0.00000047684,  0.00000083447,  0.00000154972,\n",
            "         0.00000286102,  0.00000542402,  0.00000989437,  0.00001806021,\n",
            "         0.00003272295,  0.00005859137,  0.00010222197,  0.00017261505,\n",
            "         0.00027990341,  0.00043839216,  0.00065785646,  0.00096786022,\n",
            "         0.00137037039,  0.00183957815,  0.00257247686,  0.00255656242,\n",
            "         0.00613689423, -0.01227462292,  0.02940583229,  0.00000000000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BINARY SEARCH"
      ],
      "metadata": {
        "id": "fGjhbQp6LZ2_"
      },
      "id": "fGjhbQp6LZ2_"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import Callable, Optional, List\n",
        "\n",
        "device=\"cpu\"\n",
        "dtype = torch.float64\n",
        "\n",
        "def binary_search_next_t(\n",
        "    t_i: float,\n",
        "    t_min: float,\n",
        "    q: float,\n",
        "    rr_time_schedule: Callable,\n",
        "    tol_q: float = 1e-8,\n",
        "    tol_t: float = 1e-8,\n",
        "    max_iter: int = 64,\n",
        ") -> Optional[float]:\n",
        "    \"\"\"\n",
        "    Znajduje kolejny krok czasowy t_{i+1} w (t_i, t_max], tak aby\n",
        "    rrMSE(t_i, t_{i+1}) ~= q przy użyciu wyszukiwania binarnego.\n",
        "\n",
        "    Zwraca:\n",
        "        t_{i+1} (float) albo None, jeśli nie da się sensownie\n",
        "        zmniejszyć czasu (np. już przy t_min wartość rrMSE jest zbyt mała).\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Krótka pomocnicza funkcja do policzenia rrMSE dla [t_i, t_candidate]\n",
        "    def rrMSE_for_interval(t_candidate: float) -> float:\n",
        "        time_schedule = torch.tensor(\n",
        "            [t_candidate, t_i],\n",
        "            dtype=dtype,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, t_steps = rr_time_schedule(\n",
        "            time_schedule.numel(),\n",
        "            time_schedule, dtype, device\n",
        "        )\n",
        "\n",
        "        return float(rrMSE[0].item())\n",
        "\n",
        "    # Jeśli już jesteśmy w t_min albo niemal, nie ma sensu liczyć dalej\n",
        "    if t_i <= t_min:\n",
        "        return None\n",
        "\n",
        "    # Sprawdź wartość w skrajnym punkcie t_min\n",
        "    val_at_tmin = rrMSE_for_interval(t_min)\n",
        "    print(\"Checked val at t_min vs t_i= \", val_at_tmin, t_min, t_i)\n",
        "\n",
        "    # Jeżeli nawet największy dozwolony krok przekracza q,\n",
        "    # możesz:\n",
        "    # (a) zakończyć i zwrócić None,\n",
        "    # (b) albo przyjąć t_min jako ostatni krok (komentarz niżej).\n",
        "    if val_at_tmin > q + tol_q:\n",
        "        # Wersja konserwatywna: i tak przekraczamy q\n",
        "        return None\n",
        "\n",
        "        # Wersja „domykająca” przedział: bierzemy t_max jako ostatni krok\n",
        "        return t_min\n",
        "\n",
        "    # W tym miejscu zakładamy, że funkcja rrMSE(t, t_i, t) jest\n",
        "    # (w przybliżeniu) rosnąca w t, więc możemy użyć binary search.\n",
        "    right = t_i\n",
        "    left = t_min\n",
        "    best_t = None\n",
        "    best_val = None\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        mid = 0.5 * (left + right)\n",
        "\n",
        "        # Zabezpieczenie przed nieskończoną pętlą,\n",
        "        # jeśli t się już praktycznie nie zmienia\n",
        "        if mid >= t_i - tol_t:\n",
        "            break\n",
        "\n",
        "        val_mid = rrMSE_for_interval(mid)\n",
        "\n",
        "        # Zapamiętujemy najlepsze przybliżenie do q\n",
        "        if best_val is None or abs(val_mid - q) < abs(best_val - q):\n",
        "            best_val = val_mid\n",
        "            best_t = mid\n",
        "\n",
        "        # Jeśli trafiliśmy z dokładnością do tol_q — koniec\n",
        "        if abs(val_mid - q) <= tol_q:\n",
        "            best_t = mid\n",
        "            break\n",
        "\n",
        "        # Klasyczne przeszukiwanie binarne:\n",
        "        # zakładamy rrMSE rośnie z t, więc:\n",
        "        print(left, mid, right, val_mid)\n",
        "        if val_mid < q:\n",
        "            left = mid\n",
        "        else:\n",
        "            right = mid\n",
        "\n",
        "    # Jeśli nic sensownego nie znaleźliśmy lub t się nie ruszyło — koniec\n",
        "    #if best_t is None or best_t <= t_i + tol_t:\n",
        "        #return None\n",
        "\n",
        "    return best_t\n",
        "\n",
        "\n",
        "def build_rr_schedule(\n",
        "    t_min: float,\n",
        "    t_max: float,\n",
        "    q: float,\n",
        "    rr_time_schedule: Callable,\n",
        "    tol_q: float = 1e-8,\n",
        "    tol_t: float = 1e-8,\n",
        "    max_iter_per_step: int = 64,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Buduje harmonogram czasów t_0, t_1, ..., t_K:\n",
        "    - t_0 = t_min,\n",
        "    - t_{i+1} wybierane przez wyszukiwanie binarne tak, aby rrMSE ~= q,\n",
        "    - zatrzymuje się, gdy nie da się dodać kolejnego kroku bez przekroczenia t_max.\n",
        "\n",
        "    Zwraca:\n",
        "        1D tensor z punktami czasowymi.\n",
        "    \"\"\"\n",
        "\n",
        "    times: List[float] = [float(t_max)]\n",
        "\n",
        "    while True:\n",
        "        print(\"iter\")\n",
        "        t_i = times[0]\n",
        "\n",
        "        next_t = binary_search_next_t(\n",
        "            t_i=t_i,\n",
        "            t_min=t_min,\n",
        "            q=q,\n",
        "            rr_time_schedule=rr_time_schedule,\n",
        "            tol_q=tol_q,\n",
        "            tol_t=tol_t,\n",
        "            max_iter=max_iter_per_step,\n",
        "        )\n",
        "\n",
        "        # Nie da się dodać kolejnego kroku\n",
        "        if next_t is None:\n",
        "            print(\"exi2t\")\n",
        "            break\n",
        "\n",
        "        times.insert(0, next_t)   #append at beginning\n",
        "\n",
        "        # Jeśli praktycznie doszliśmy do t_min to koniec\n",
        "        if next_t <= t_min - tol_t:\n",
        "            print(\"exit\")\n",
        "            break\n",
        "\n",
        "    return torch.tensor(times, dtype=dtype, device=device)\n"
      ],
      "metadata": {
        "id": "nQ1RpQebLckf"
      },
      "id": "nQ1RpQebLckf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_min = 1e-8\n",
        "t_max = 1-1e-8\n",
        "q = 0.53  # Twój docelowy rrMSE\n",
        "\n",
        "time_schedule = build_rr_schedule(\n",
        "    t_min=t_min,\n",
        "    t_max=t_max,\n",
        "    q=q,\n",
        "    rr_time_schedule=rr_time_schedule,\n",
        ")\n",
        "\n",
        "\n",
        "print(time_schedule)\n",
        "print(time_schedule.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwlHSar1LyQz",
        "outputId": "3768ae54-141a-4fde-99b5-a909ad354d04"
      },
      "id": "YwlHSar1LyQz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter\n",
            "Checked val at t_min vs t_i=  1.7901728496891406e-10 1e-08 0.99999999\n",
            "1e-08 0.5 0.99999999 1.3353602733993091e-05\n",
            "0.5 0.749999995 0.99999999 5.145389169059657e-05\n",
            "0.749999995 0.8749999925 0.99999999 0.0001332681500292721\n",
            "0.8749999925 0.9374999912499999 0.99999999 0.0002871136666001679\n",
            "0.9374999912499999 0.9687499906249999 0.99999999 0.0005539537030705763\n",
            "0.9687499906249999 0.9843749903124999 0.99999999 0.0009916315993864896\n",
            "0.9843749903124999 0.99218749015625 0.99999999 0.001680267266330853\n",
            "0.99218749015625 0.9960937400781249 0.99999999 0.002729066060415637\n",
            "0.9960937400781249 0.9980468650390624 0.99999999 0.004284847353602783\n",
            "0.9980468650390624 0.9990234275195311 0.99999999 0.00654265948896223\n",
            "0.9990234275195311 0.9995117087597656 0.99999999 0.009758913837479642\n",
            "0.9995117087597656 0.9997558493798828 0.99999999 0.014267543077754474\n",
            "0.9997558493798828 0.9998779196899414 0.99999999 0.020499761196118144\n",
            "0.9998779196899414 0.9999389548449706 0.99999999 0.029008057354009045\n",
            "0.9999389548449706 0.9999694724224852 0.99999999 0.040495043088143286\n",
            "0.9999694724224852 0.9999847312112427 0.99999999 0.0558475657050645\n",
            "0.9999847312112427 0.9999923606056214 0.99999999 0.07617577677768916\n",
            "0.9999923606056214 0.9999961753028106 0.99999999 0.10285480149502131\n",
            "0.9999961753028106 0.9999980826514052 0.99999999 0.13756133932613\n",
            "0.9999980826514052 0.9999990363257025 0.99999999 0.18228437409791112\n",
            "0.9999990363257025 0.9999995131628512 0.99999999 0.23925831821170784\n",
            "0.9999995131628512 0.9999997515814256 0.99999999 0.31070077773084537\n",
            "0.9999997515814256 0.9999998707907127 0.99999999 0.398121244951687\n",
            "0.9999998707907127 0.9999999303953564 0.99999999 0.5008677596093595\n",
            "0.9999999303953564 0.9999999601976781 0.99999999 0.6138846304001173\n",
            "0.9999999303953564 0.9999999452965173 0.9999999601976781 0.5470225585691906\n",
            "0.9999999303953564 0.9999999378459368 0.9999999452965173 0.5220973120315728\n",
            "0.9999999378459368 0.9999999415712271 0.9999999452965173 0.5340301115477595\n",
            "0.9999999378459368 0.9999999397085819 0.9999999415712271 0.5279408253707527\n",
            "0.9999999397085819 0.9999999406399045 0.9999999415712271 0.5309536286831358\n",
            "0.9999999397085819 0.9999999401742432 0.9999999406399045 0.5294394113708341\n",
            "0.9999999401742432 0.9999999404070739 0.9999999406399045 0.5301945483694094\n",
            "0.9999999401742432 0.9999999402906585 0.9999999404070739 0.5298164891906592\n",
            "0.9999999402906585 0.9999999403488662 0.9999999404070739 0.5300053958315092\n",
            "0.9999999402906585 0.9999999403197624 0.9999999403488662 0.5299109118075821\n",
            "0.9999999403197624 0.9999999403343143 0.9999999403488662 0.5299581461433325\n",
            "0.9999999403343143 0.9999999403415902 0.9999999403488662 0.5299817690631894\n",
            "0.9999999403415902 0.9999999403452282 0.9999999403488662 0.5299935819696217\n",
            "0.9999999403452282 0.9999999403470472 0.9999999403488662 0.529999488781743\n",
            "0.9999999403470472 0.9999999403479567 0.9999999403488662 0.530002442277846\n",
            "0.9999999403470472 0.999999940347502 0.9999999403479567 0.5300009655210548\n",
            "0.9999999403470472 0.9999999403472746 0.999999940347502 0.5300002271470519\n",
            "0.9999999403470472 0.9999999403471609 0.9999999403472746 0.5299998579651639\n",
            "0.9999999403471609 0.9999999403472177 0.9999999403472746 0.5300000425559906\n",
            "0.9999999403471609 0.9999999403471893 0.9999999403472177 0.5299999502593126\n",
            "iter\n",
            "Checked val at t_min vs t_i=  3.3760103450177476e-10 1e-08 0.9999999403472035\n",
            "1e-08 0.4999999751736018 0.9999999403472035 2.519472731858805e-05\n",
            "0.4999999751736018 0.7499999577604026 0.9999999403472035 9.708104923378521e-05\n",
            "0.7499999577604026 0.8749999490538031 0.9999999403472035 0.0002514462706332293\n",
            "0.8749999490538031 0.9374999447005032 0.9999999403472035 0.0005417192705690691\n",
            "0.9374999447005032 0.9687499425238534 0.9999999403472035 0.0010451890939901893\n",
            "0.9687499425238534 0.9843749414355285 0.9999999403472035 0.001870993193491904\n",
            "0.9843749414355285 0.992187440891366 0.9999999403472035 0.0031702976888253196\n",
            "0.992187440891366 0.9960936906192848 0.9999999403472035 0.005149138898775093\n",
            "0.9960936906192848 0.9980468154832441 0.9999999403472035 0.008084499994391781\n",
            "0.9980468154832441 0.9990233779152238 0.9999999403472035 0.012344297714017299\n",
            "0.9990233779152238 0.9995116591312136 0.9999999403472035 0.018412051002691644\n",
            "0.9995116591312136 0.9997557997392086 0.9999999403472035 0.026917066046674865\n",
            "0.9997557997392086 0.999877870043206 0.9999999403472035 0.03867091665993162\n",
            "0.999877870043206 0.9999389051952048 0.9999999403472035 0.05471060456387452\n",
            "0.9999389051952048 0.9999694227712042 0.9999999403472035 0.07634748846930632\n",
            "0.9999694227712042 0.9999846815592038 0.9999999403472035 0.10521746949973093\n",
            "0.9999846815592038 0.9999923109532036 0.9999999403472035 0.14331861652245942\n",
            "0.9999923109532036 0.9999961256502036 0.9999999403472035 0.19299963884650093\n",
            "0.9999961256502036 0.9999980329987035 0.9999999403472035 0.25681065560241073\n",
            "0.9999980329987035 0.9999989866729535 0.9999999403472035 0.33702421987248704\n",
            "0.9999989866729535 0.9999994635100785 0.9999999403472035 0.43449024458447305\n",
            "0.9999994635100785 0.9999997019286411 0.9999999403472035 0.5465239841058502\n",
            "0.9999994635100785 0.9999995827193597 0.9999997019286411 0.47955966301282144\n",
            "0.9999995827193597 0.9999996423240004 0.9999997019286411 0.5092563273277433\n",
            "0.9999996423240004 0.9999996721263207 0.9999997019286411 0.5267447024229025\n",
            "0.9999996721263207 0.9999996870274809 0.9999997019286411 0.536316267887809\n",
            "0.9999996721263207 0.9999996795769008 0.9999996870274809 0.5314553145078971\n",
            "0.9999996721263207 0.9999996758516108 0.9999996795769008 0.5290817226867404\n",
            "0.9999996758516108 0.9999996777142558 0.9999996795769008 0.5302638853204867\n",
            "0.9999996758516108 0.9999996767829333 0.9999996777142558 0.5296716535413709\n",
            "0.9999996767829333 0.9999996772485946 0.9999996777142558 0.5299674808687899\n",
            "0.9999996772485946 0.9999996774814253 0.9999996777142558 0.5301156108623423\n",
            "0.9999996772485946 0.9999996773650099 0.9999996774814253 0.5300415278117592\n",
            "0.9999996772485946 0.9999996773068023 0.9999996773650099 0.5300044998315107\n",
            "0.9999996772485946 0.9999996772776985 0.9999996773068023 0.5299859892201075\n",
            "0.9999996772776985 0.9999996772922504 0.9999996773068023 0.5299952442451232\n",
            "0.9999996772922504 0.9999996772995263 0.9999996773068023 0.5299998719653616\n",
            "0.9999996772995263 0.9999996773031643 0.9999996773068023 0.5300021858808144\n",
            "0.9999996772995263 0.9999996773013453 0.9999996773031643 0.5300010289199181\n",
            "0.9999996772995263 0.9999996773004358 0.9999996773013453 0.5300004504415378\n",
            "0.9999996772995263 0.9999996772999811 0.9999996773004358 0.5300001612044093\n",
            "0.9999996772995263 0.9999996772997537 0.9999996772999811 0.5300000165848168\n",
            "0.9999996772995263 0.99999967729964 0.9999996772997537 0.5299999442750709\n",
            "0.99999967729964 0.9999996772996969 0.9999996772997537 0.5299999804324113\n",
            "iter\n",
            "Checked val at t_min vs t_i=  6.365970880742027e-10 1e-08 0.9999996772997253\n",
            "1e-08 0.49999984364986266 0.9999996772997253 4.753606762346586e-05\n",
            "0.49999984364986266 0.749999760474794 0.9999996772997253 0.00018316905694333474\n",
            "0.749999760474794 0.8749997188872596 0.9999996772997253 0.00047442186864900536\n",
            "0.8749997188872596 0.9374996980934924 0.9999996772997253 0.001022102608660958\n",
            "0.9374996980934924 0.9687496876966089 0.9999996772997253 0.001972035527919539\n",
            "0.9687496876966089 0.9843746824981671 0.9999996772997253 0.003530126601381856\n",
            "0.9843746824981671 0.9921871798989461 0.9999996772997253 0.005981552420976783\n",
            "0.9921871798989461 0.9960934285993357 0.9999996772997253 0.009714935246917644\n",
            "0.9960934285993357 0.9980465529495305 0.9999996772997253 0.015252524978280274\n",
            "0.9980465529495305 0.9990231151246278 0.9999996772997253 0.023287494667657622\n",
            "0.9990231151246278 0.9995113962121766 0.9999996772997253 0.034729359825415286\n",
            "0.9995113962121766 0.999755536755951 0.9999996772997253 0.050757918728485084\n",
            "0.999755536755951 0.9998776070278381 0.9999996772997253 0.07288411202419826\n",
            "0.9998776070278381 0.9999386421637817 0.9999996772997253 0.10301063649198693\n",
            "0.9999386421637817 0.9999691597317535 0.9999996772997253 0.14347076385264831\n",
            "0.9999691597317535 0.9999844185157394 0.9999996772997253 0.1969888609807748\n",
            "0.9999844185157394 0.9999920479077323 0.9999996772997253 0.26642853021243007\n",
            "0.9999920479077323 0.9999958626037289 0.9999996772997253 0.35405195016820856\n",
            "0.9999958626037289 0.9999977699517271 0.9999996772997253 0.4598725872295362\n",
            "0.9999977699517271 0.9999987236257262 0.9999996772997253 0.5789889270153384\n",
            "0.9999977699517271 0.9999982467887266 0.9999987236257262 0.5082139386827712\n",
            "0.9999982467887266 0.9999984852072263 0.9999987236257262 0.5397738484857192\n",
            "0.9999982467887266 0.9999983659979765 0.9999984852072263 0.5232040450776548\n",
            "0.9999983659979765 0.9999984256026014 0.9999984852072263 0.5312739315971604\n",
            "0.9999983659979765 0.9999983958002889 0.9999984256026014 0.5271875994957667\n",
            "0.9999983958002889 0.9999984107014452 0.9999984256026014 0.5292176343600197\n",
            "0.9999984107014452 0.9999984181520234 0.9999984256026014 0.5302424637082753\n",
            "0.9999984107014452 0.9999984144267343 0.9999984181520234 0.5297292238197407\n",
            "0.9999984144267343 0.9999984162893789 0.9999984181520234 0.5299856368968405\n",
            "0.9999984162893789 0.9999984172207012 0.9999984181520234 0.5301139985126331\n",
            "0.9999984162893789 0.99999841675504 0.9999984172207012 0.5300498047595223\n",
            "0.9999984162893789 0.9999984165222094 0.99999841675504 0.5300177175921337\n",
            "0.9999984162893789 0.9999984164057942 0.9999984165222094 0.5300016764438821\n",
            "0.9999984162893789 0.9999984163475866 0.9999984164057942 0.5299936564695505\n",
            "0.9999984163475866 0.9999984163766904 0.9999984164057942 0.5299976664062026\n",
            "0.9999984163766904 0.9999984163912423 0.9999984164057942 0.5299996714124136\n",
            "0.9999984163912423 0.9999984163985183 0.9999984164057942 0.5300006739237542\n",
            "0.9999984163912423 0.9999984163948803 0.9999984163985183 0.5300001726660584\n",
            "0.9999984163912423 0.9999984163930613 0.9999984163948803 0.529999922039039\n",
            "0.9999984163930613 0.9999984163939708 0.9999984163948803 0.5300000473537354\n",
            "0.9999984163930613 0.999998416393516 0.9999984163939708 0.5299999846963749\n",
            "0.999998416393516 0.9999984163937434 0.9999984163939708 0.5300000160250519\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.2005411696569216e-09 1e-08 0.9999984163936297\n",
            "1e-08 0.4999992131968149 0.9999984163936297 8.968874785153975e-05\n",
            "0.4999992131968149 0.7499988147952223 0.9999984163936297 0.00034559646732319933\n",
            "0.7499988147952223 0.874998615594426 0.9999984163936297 0.0008951210269211697\n",
            "0.874998615594426 0.9374985159940279 0.9999984163936297 0.0019284532879544549\n",
            "0.9374985159940279 0.9687484661938288 0.9999984163936297 0.0037206903867194408\n",
            "0.9687484661938288 0.9843734412937293 0.9999984163936297 0.006660201036544914\n",
            "0.9843734412937293 0.9921859288436795 0.9999984163936297 0.011284656980317909\n",
            "0.9921859288436795 0.9960921726186547 0.9999984163936297 0.018326154403561713\n",
            "0.9960921726186547 0.9980452945061422 0.9999984163936297 0.028766793857447247\n",
            "0.9980452945061422 0.999021855449886 0.9999984163936297 0.04390530616532125\n",
            "0.999021855449886 0.9995101359217579 0.9999984163936297 0.06543265146537756\n",
            "0.9995101359217579 0.9997542761576939 0.9999984163936297 0.0955069809837518\n",
            "0.9997542761576939 0.9998763462756618 0.9999984163936297 0.1367986838942745\n",
            "0.9998763462756618 0.9999373813346457 0.9999984163936297 0.19242845598449065\n",
            "0.9999373813346457 0.9999678988641377 0.9999984163936297 0.26561721022663276\n",
            "0.9999678988641377 0.9999831576288838 0.9999984163936297 0.35868836505116747\n",
            "0.9999831576288838 0.9999907870112568 0.9999984163936297 0.47094836489884595\n",
            "0.9999907870112568 0.9999946017024433 0.9999984163936297 0.5956031961669997\n",
            "0.9999907870112568 0.99999269435685 0.9999946017024433 0.5218442093126452\n",
            "0.99999269435685 0.9999936480296466 0.9999946017024433 0.554861508087218\n",
            "0.99999269435685 0.9999931711932484 0.9999936480296466 0.5375497985274804\n",
            "0.99999269435685 0.9999929327750492 0.9999931711932484 0.5295124559125753\n",
            "0.9999929327750492 0.9999930519841488 0.9999931711932484 0.5334831100023188\n",
            "0.9999929327750492 0.9999929923795989 0.9999930519841488 0.5314860221067899\n",
            "0.9999929327750492 0.9999929625773241 0.9999929923795989 0.5304963284653602\n",
            "0.9999929327750492 0.9999929476761866 0.9999929625773241 0.530003668215328\n",
            "0.9999929327750492 0.9999929402256179 0.9999929476761866 0.5297578815273448\n",
            "0.9999929402256179 0.9999929439509023 0.9999929476761866 0.5298807296828915\n",
            "0.9999929439509023 0.9999929458135445 0.9999929476761866 0.529942187642893\n",
            "0.9999929458135445 0.9999929467448656 0.9999929476761866 0.5299729251062798\n",
            "0.9999929467448656 0.9999929472105261 0.9999929476761866 0.529988295952673\n",
            "0.9999929472105261 0.9999929474433564 0.9999929476761866 0.5299959819078597\n",
            "0.9999929474433564 0.9999929475597715 0.9999929476761866 0.5299998250174077\n",
            "0.9999929475597715 0.9999929476179791 0.9999929476761866 0.5300017466065565\n",
            "0.9999929475597715 0.9999929475888754 0.9999929476179791 0.5300007858110538\n",
            "0.9999929475597715 0.9999929475743234 0.9999929475888754 0.5300003054135405\n",
            "0.9999929475597715 0.9999929475670475 0.9999929475743234 0.5300000652165374\n",
            "0.9999929475597715 0.9999929475634095 0.9999929475670475 0.529999945119401\n",
            "iter\n",
            "Checked val at t_min vs t_i=  2.2642806716622226e-09 1e-08 0.9999929475652285\n",
            "1e-08 0.4999964787826143 0.9999929475652285 0.00016921933122382129\n",
            "0.4999964787826143 0.7499947131739214 0.9999929475652285 0.000652047448737878\n",
            "0.7499947131739214 0.874993830369575 0.9999929475652285 0.0016888237979047506\n",
            "0.874993830369575 0.9374933889674018 0.9999929475652285 0.0036382853313140103\n",
            "0.9374933889674018 0.9687431682663151 0.9999929475652285 0.007019121376205348\n",
            "0.9687431682663151 0.9843680579157719 0.9999929475652285 0.012562998392109675\n",
            "0.9843680579157719 0.9921805027405002 0.9999929475652285 0.021281121097101646\n",
            "0.9921805027405002 0.9960867251528643 0.9999929475652285 0.034545357063588085\n",
            "0.9960867251528643 0.9980398363590464 0.9999929475652285 0.05418201004023911\n",
            "0.9980398363590464 0.9990163919621374 0.9999929475652285 0.08256742682618827\n",
            "0.9990163919621374 0.9995046697636829 0.9999929475652285 0.12269086942050302\n",
            "0.9995046697636829 0.9997488086644557 0.9999929475652285 0.17809168911176904\n",
            "0.9997488086644557 0.9998708781148421 0.9999929475652285 0.25245055667157035\n",
            "0.9998708781148421 0.9999319128400352 0.9999929475652285 0.348402266479264\n",
            "0.9999319128400352 0.9999624302026319 0.9999929475652285 0.46503614379281927\n",
            "0.9999624302026319 0.9999776888839302 0.9999929475652285 0.5944326007653862\n",
            "0.9999624302026319 0.999970059543281 0.9999776888839302 0.5179513423930296\n",
            "0.999970059543281 0.9999738742136056 0.9999776888839302 0.5522288048064893\n",
            "0.999970059543281 0.9999719668784433 0.9999738742136056 0.5342631665594324\n",
            "0.999970059543281 0.9999710132108621 0.9999719668784433 0.525916963488698\n",
            "0.9999710132108621 0.9999714900446527 0.9999719668784433 0.5300405838757303\n",
            "0.9999710132108621 0.9999712516277575 0.9999714900446527 0.5279666503416565\n",
            "0.9999712516277575 0.999971370836205 0.9999714900446527 0.5290005559503481\n",
            "0.999971370836205 0.9999714304404288 0.9999714900446527 0.5295198007851688\n",
            "0.9999714304404288 0.9999714602425407 0.9999714900446527 0.5297799995623903\n",
            "0.9999714602425407 0.9999714751435966 0.9999714900446527 0.5299102434667808\n",
            "0.9999714751435966 0.9999714825941246 0.9999714900446527 0.5299754015990091\n",
            "0.9999714825941246 0.9999714863193887 0.9999714900446527 0.5300079897192763\n",
            "0.9999714825941246 0.9999714844567567 0.9999714863193887 0.5299916949046168\n",
            "0.9999714844567567 0.9999714853880727 0.9999714863193887 0.5299998421245369\n",
            "0.9999714853880727 0.9999714858537307 0.9999714863193887 0.5300039158752289\n",
            "0.9999714853880727 0.9999714856209017 0.9999714858537307 0.5300018789851353\n",
            "0.9999714853880727 0.9999714855044872 0.9999714856209017 0.5300008605548446\n",
            "0.9999714853880727 0.99997148544628 0.9999714855044872 0.5300003513394398\n",
            "0.9999714853880727 0.9999714854171764 0.99997148544628 0.5300000967310534\n",
            "0.9999714853880727 0.9999714854026245 0.9999714854171764 0.5299999694284989\n",
            "0.9999714854026245 0.9999714854099004 0.9999714854171764 0.5300000330785296\n",
            "iter\n",
            "Checked val at t_min vs t_i=  4.270730074504177e-09 1e-08 0.9999714854062625\n",
            "1e-08 0.49998574770313126 0.9999714854062625 0.0003192612412308121\n",
            "0.49998574770313126 0.7499786165546969 0.9999714854062625 0.001230148300951863\n",
            "0.7499786165546969 0.8749750509804797 0.9999714854062625 0.0031858753751581362\n",
            "0.8749750509804797 0.9374732681933711 0.9999714854062625 0.00686245099325859\n",
            "0.9374732681933711 0.9687223767998168 0.9999714854062625 0.013235839315044831\n",
            "0.9687223767998168 0.9843469311030396 0.9999714854062625 0.023678356351222087\n",
            "0.9843469311030396 0.9921592082546511 0.9999714854062625 0.040073807594195515\n",
            "0.9921592082546511 0.9960653468304568 0.9999714854062625 0.06494135745852142\n",
            "0.9960653468304568 0.9980184161183596 0.9999714854062625 0.1015330964229715\n",
            "0.9980184161183596 0.998994950762311 0.9999714854062625 0.15380662885704996\n",
            "0.998994950762311 0.9994832180842868 0.9999714854062625 0.22603164149760885\n",
            "0.9994832180842868 0.9997273517452746 0.9999714854062625 0.32154371473889487\n",
            "0.9997273517452746 0.9998494185757685 0.9999714854062625 0.4400150288204734\n",
            "0.9998494185757685 0.9999104519910155 0.9999714854062625 0.573544098360124\n",
            "0.9998494185757685 0.999879935283392 0.9999104519910155 0.49439716285412766\n",
            "0.999879935283392 0.9998951936372038 0.9999104519910155 0.5297960599397106\n",
            "0.9998951936372038 0.9999028228141096 0.9999104519910155 0.5504293197649309\n",
            "0.9998951936372038 0.9998990082256567 0.9999028228141096 0.5398311135993771\n",
            "0.9998951936372038 0.9998971009314302 0.9998990082256567 0.5347463704141908\n",
            "0.9998951936372038 0.9998961472843171 0.9998971009314302 0.5322547864123647\n",
            "0.9998951936372038 0.9998956704607604 0.9998961472843171 0.5310213616171009\n",
            "0.9998951936372038 0.9998954320489821 0.9998956704607604 0.530407701011172\n",
            "0.9998951936372038 0.999895312843093 0.9998954320489821 0.5301016287354773\n",
            "0.9998951936372038 0.9998952532401484 0.999895312843093 0.5299487814874477\n",
            "0.9998952532401484 0.9998952830416207 0.999895312843093 0.5300251893871354\n",
            "0.9998952532401484 0.9998952681408846 0.9998952830416207 0.5299869815080201\n",
            "0.9998952681408846 0.9998952755912527 0.9998952830416207 0.5300060844651971\n",
            "0.9998952681408846 0.9998952718660686 0.9998952755912527 0.5299965327434703\n",
            "0.9998952718660686 0.9998952737286606 0.9998952755912527 0.5300013085452581\n",
            "0.9998952718660686 0.9998952727973647 0.9998952737286606 0.5299989206279198\n",
            "0.9998952727973647 0.9998952732630126 0.9998952737286606 0.5300001145815153\n",
            "0.9998952727973647 0.9998952730301887 0.9998952732630126 0.5299995176025225\n",
            "0.9998952730301887 0.9998952731466006 0.9998952732630126 0.529999816093015\n",
            "0.9998952731466006 0.9998952732048066 0.9998952732630126 0.5299999653359688\n",
            "0.9998952732048066 0.9998952732339097 0.9998952732630126 0.5300000399613416\n",
            "iter\n",
            "Checked val at t_min vs t_i=  8.055613973253412e-09 1e-08 0.9998952732193582\n",
            "1e-08 0.49994764160967914 0.9998952732193582 0.0006022602418992026\n",
            "0.49994764160967914 0.7499214574145187 0.9998952732193582 0.0023201950595608304\n",
            "0.7499214574145187 0.8749083653169385 0.9998952732193582 0.006007197807327514\n",
            "0.8749083653169385 0.9374018192681484 0.9998952732193582 0.012933028115930955\n",
            "0.9374018192681484 0.9686485462437533 0.9998952732193582 0.024921122048580643\n",
            "0.9686485462437533 0.9842719097315558 0.9998952732193582 0.0445063705376295\n",
            "0.9842719097315558 0.992083591475457 0.9998952732193582 0.07508443807622213\n",
            "0.992083591475457 0.9959894323474077 0.9998952732193582 0.1209616010566142\n",
            "0.9959894323474077 0.997942352783383 0.9998952732193582 0.18707018416299737\n",
            "0.997942352783383 0.9989188130013706 0.9998952732193582 0.2778430622568835\n",
            "0.9989188130013706 0.9994070431103644 0.9998952732193582 0.3944913530142352\n",
            "0.9994070431103644 0.9996511581648613 0.9998952732193582 0.5306359892895863\n",
            "0.9994070431103644 0.9995291006376128 0.9996511581648613 0.449358988073398\n",
            "0.9995291006376128 0.999590129401237 0.9996511581648613 0.4855026912155248\n",
            "0.999590129401237 0.9996206437830492 0.9996511581648613 0.506725205126039\n",
            "0.9996206437830492 0.9996359009739553 0.9996511581648613 0.5183101087424493\n",
            "0.9996359009739553 0.9996435295694083 0.9996511581648613 0.524375566891247\n",
            "0.9996435295694083 0.9996473438671347 0.9996511581648613 0.5274807605241205\n",
            "0.9996473438671347 0.999649251015998 0.9996511581648613 0.529052036987089\n",
            "0.999649251015998 0.9996502045904296 0.9996511581648613 0.5298424180481779\n",
            "0.9996502045904296 0.9996506813776455 0.9996511581648613 0.5302388035603832\n",
            "0.9996502045904296 0.9996504429840376 0.9996506813776455 0.5300405109414825\n",
            "0.9996502045904296 0.9996503237872336 0.9996504429840376 0.5299414395506539\n",
            "0.9996503237872336 0.9996503833856356 0.9996504429840376 0.5299909690061756\n",
            "0.9996503833856356 0.9996504131848366 0.9996504429840376 0.5300157384150738\n",
            "0.9996503833856356 0.999650398285236 0.9996504131848366 0.5300033533243291\n",
            "0.9996503833856356 0.9996503908354358 0.999650398285236 0.5299971610677685\n",
            "0.9996503908354358 0.9996503945603359 0.999650398285236 0.5300002571716308\n",
            "0.9996503908354358 0.9996503926978859 0.9996503945603359 0.5299987091124169\n",
            "0.9996503926978859 0.9996503936291109 0.9996503945603359 0.5299994831392648\n",
            "0.9996503936291109 0.9996503940947234 0.9996503945603359 0.5299998701538776\n",
            "0.9996503940947234 0.9996503943275297 0.9996503945603359 0.5300000636626592\n",
            "0.9996503940947234 0.9996503942111266 0.9996503943275297 0.5299999669107158\n",
            "0.9996503942111266 0.9996503942693281 0.9996503943275297 0.5300000152879176\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.5195559769863687e-08 1e-08 0.9996503942402273\n",
            "1e-08 0.49982520212011367 0.9996503942402273 0.001135637599741029\n",
            "0.49982520212011367 0.7497377981801705 0.9996503942402273 0.0043726706073129295\n",
            "0.7497377981801705 0.8746940962101989 0.9996503942402273 0.011310815633957479\n",
            "0.8746940962101989 0.9371722452252131 0.9996503942402273 0.024311336080676895\n",
            "0.9371722452252131 0.9684113197327202 0.9996503942402273 0.04670710944993237\n",
            "0.9684113197327202 0.9840308569864737 0.9996503942402273 0.08296117260670173\n",
            "0.9840308569864737 0.9918406256133505 0.9996503942402273 0.13857598134736265\n",
            "0.9918406256133505 0.9957455099267889 0.9996503942402273 0.21928070976616099\n",
            "0.9957455099267889 0.9976979520835081 0.9996503942402273 0.32865230104948767\n",
            "0.9976979520835081 0.9986741731618677 0.9996503942402273 0.4635638612436138\n",
            "0.9986741731618677 0.9991622837010474 0.9996503942402273 0.6096458236920613\n",
            "0.9986741731618677 0.9989182284314575 0.9991622837010474 0.5240651113045028\n",
            "0.9989182284314575 0.9990402560662525 0.9991622837010474 0.5627407739423371\n",
            "0.9989182284314575 0.998979242248855 0.9990402560662525 0.5425285196359609\n",
            "0.9989182284314575 0.9989487353401563 0.998979242248855 0.5330940599533592\n",
            "0.9989182284314575 0.9989334818858069 0.9989487353401563 0.5285307049705701\n",
            "0.9989334818858069 0.9989411086129816 0.9989487353401563 0.5307999433456647\n",
            "0.9989334818858069 0.9989372952493942 0.9989411086129816 0.5296622421758543\n",
            "0.9989372952493942 0.9989392019311879 0.9989411086129816 0.5302303188185099\n",
            "0.9989372952493942 0.9989382485902911 0.9989392019311879 0.529946087440832\n",
            "0.9989382485902911 0.9989387252607396 0.9989392019311879 0.5300881548110092\n",
            "0.9989382485902911 0.9989384869255153 0.9989387252607396 0.5300171090557843\n",
            "0.9989382485902911 0.9989383677579032 0.9989384869255153 0.5299815952309999\n",
            "0.9989383677579032 0.9989384273417092 0.9989384869255153 0.5299993513901788\n",
            "0.9989384273417092 0.9989384571336123 0.9989384869255153 0.5300082300331241\n",
            "0.9989384273417092 0.9989384422376608 0.9989384571336123 0.5300037906645142\n",
            "0.9989384273417092 0.998938434789685 0.9989384422376608 0.530001571016794\n",
            "0.9989384273417092 0.9989384310656971 0.998938434789685 0.5300004611993032\n",
            "0.9989384273417092 0.9989384292037031 0.9989384310656971 0.5299999062927521\n",
            "0.9989384292037031 0.9989384301347002 0.9989384310656971 0.5300001837495673\n",
            "0.9989384292037031 0.9989384296692017 0.9989384301347002 0.5300000450198783\n",
            "0.9989384292037031 0.9989384294364524 0.9989384296692017 0.5299999756587752\n",
            "0.9989384294364524 0.998938429552827 0.9989384296692017 0.5300000103380711\n",
            "iter\n",
            "Checked val at t_min vs t_i=  2.8664734840620283e-08 1e-08 0.9989384294946397\n",
            "1e-08 0.4994692197473199 0.9989384294946397 0.0021388870854953516\n",
            "0.4994692197473199 0.7492038246209798 0.9989384294946397 0.008222685159177076\n",
            "0.7492038246209798 0.8740711270578098 0.9989384294946397 0.021212896833177577\n",
            "0.8740711270578098 0.9365047782762248 0.9989384294946397 0.04537946398013178\n",
            "0.9365047782762248 0.9677216038854323 0.9989384294946397 0.08644664582981919\n",
            "0.9677216038854323 0.9833300166900361 0.9989384294946397 0.1512331684072645\n",
            "0.9833300166900361 0.9911342230923379 0.9989384294946397 0.24597776350200454\n",
            "0.9911342230923379 0.9950363262934888 0.9989384294946397 0.3722564875161263\n",
            "0.9950363262934888 0.9969873778940643 0.9989384294946397 0.520968048648756\n",
            "0.9969873778940643 0.997962903694352 0.9989384294946397 0.6702129480683016\n",
            "0.9969873778940643 0.9974751407942082 0.997962903694352 0.58438986626565\n",
            "0.9969873778940643 0.9972312593441363 0.9974751407942082 0.5505084934374235\n",
            "0.9969873778940643 0.9971093186191002 0.9972312593441363 0.5352537466583918\n",
            "0.9969873778940643 0.9970483482565823 0.9971093186191002 0.5279961019654104\n",
            "0.9970483482565823 0.9970788334378413 0.9971093186191002 0.5315954697440973\n",
            "0.9970483482565823 0.9970635908472119 0.9970788334378413 0.5297885188178701\n",
            "0.9970635908472119 0.9970712121425266 0.9970788334378413 0.5306901655837888\n",
            "0.9970635908472119 0.9970674014948693 0.9970712121425266 0.530238886525746\n",
            "0.9970635908472119 0.9970654961710406 0.9970674014948693 0.5300135889435892\n",
            "0.9970635908472119 0.9970645435091262 0.9970654961710406 0.5299010254698217\n",
            "0.9970645435091262 0.9970650198400834 0.9970654961710406 0.5299573001013821\n",
            "0.9970650198400834 0.997065258005562 0.9970654961710406 0.5299854427445536\n",
            "0.997065258005562 0.9970653770883013 0.9970654961710406 0.529999515396151\n",
            "0.9970653770883013 0.997065436629671 0.9970654961710406 0.5300065520588095\n",
            "0.9970653770883013 0.9970654068589861 0.997065436629671 0.5300030336997159\n",
            "0.9970653770883013 0.9970653919736437 0.9970654068589861 0.5300012745459352\n",
            "0.9970653770883013 0.9970653845309725 0.9970653919736437 0.5300003949717729\n",
            "0.9970653770883013 0.9970653808096369 0.9970653845309725 0.529999955183528\n",
            "0.9970653808096369 0.9970653826703046 0.9970653845309725 0.5300001750775356\n",
            "0.9970653808096369 0.9970653817399708 0.9970653826703046 0.5300000651305116\n",
            "0.9970653808096369 0.9970653812748038 0.9970653817399708 0.5300000101570063\n",
            "0.9970653808096369 0.9970653810422203 0.9970653812748038 0.5299999826727307\n",
            "iter\n",
            "Checked val at t_min vs t_i=  5.4074846576351284e-08 1e-08 0.9970653811585121\n",
            "1e-08 0.49853269557925606 0.9970653811585121 0.004016731778335284\n",
            "0.49853269557925606 0.7477990383688841 0.9970653811585121 0.015378409771512233\n",
            "0.7477990383688841 0.8724322097636981 0.9970653811585121 0.03939828485889818\n",
            "0.8724322097636981 0.9347487954611051 0.9970653811585121 0.0832655255244431\n",
            "0.9347487954611051 0.9659070883098086 0.9970653811585121 0.15529634043662227\n",
            "0.9659070883098086 0.9814862347341604 0.9970653811585121 0.2620924889552025\n",
            "0.9814862347341604 0.9892758079463362 0.9970653811585121 0.40252875155750295\n",
            "0.9892758079463362 0.9931705945524241 0.9970653811585121 0.5611538538683575\n",
            "0.9892758079463362 0.9912232012493801 0.9931705945524241 0.46758220510884957\n",
            "0.9912232012493801 0.9921968979009022 0.9931705945524241 0.5096701199834327\n",
            "0.9921968979009022 0.9926837462266631 0.9931705945524241 0.53403800041612\n",
            "0.9921968979009022 0.9924403220637826 0.9926837462266631 0.5215390615958354\n",
            "0.9924403220637826 0.9925620341452228 0.9926837462266631 0.5277064778211398\n",
            "0.9925620341452228 0.992622890185943 0.9926837462266631 0.530851291767489\n",
            "0.9925620341452228 0.9925924621655828 0.992622890185943 0.52927370320244\n",
            "0.9925924621655828 0.992607676175763 0.992622890185943 0.5300611952446777\n",
            "0.9925924621655828 0.9926000691706729 0.992607676175763 0.5296671245227141\n",
            "0.9926000691706729 0.9926038726732179 0.992607676175763 0.5298640786022527\n",
            "0.9926038726732179 0.9926057744244905 0.992607676175763 0.529962616585675\n",
            "0.9926057744244905 0.9926067253001267 0.992607676175763 0.5300119008324479\n",
            "0.9926057744244905 0.9926062498623086 0.9926067253001267 0.5299872574392074\n",
            "0.9926062498623086 0.9926064875812177 0.9926067253001267 0.5299995788143238\n",
            "0.9926064875812177 0.9926066064406722 0.9926067253001267 0.5300057397439331\n",
            "0.9926064875812177 0.992606547010945 0.9926066064406722 0.5300026592617375\n",
            "0.9926064875812177 0.9926065172960814 0.992606547010945 0.5300011190355398\n",
            "0.9926064875812177 0.9926065024386496 0.9926065172960814 0.5300003489236905\n",
            "0.9926064875812177 0.9926064950099336 0.9926065024386496 0.5299999638724019\n",
            "0.9926064950099336 0.9926064987242915 0.9926065024386496 0.5300001563979657\n",
            "0.9926064950099336 0.9926064968671126 0.9926064987242915 0.5300000601339284\n",
            "0.9926064950099336 0.992606495938523 0.9926064968671126 0.5300000120019216\n",
            "0.9926064950099336 0.9926064954742283 0.992606495938523 0.5299999879334529\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.0201263336786634e-07 1e-08 0.9926064957063756\n",
            "1e-08 0.4963032528531878 0.9926064957063756 0.00749451381047671\n",
            "0.4963032528531878 0.7444548742797817 0.9926064957063756 0.0284164879164795\n",
            "0.7444548742797817 0.8685306849930787 0.9926064957063756 0.07163781751846537\n",
            "0.8685306849930787 0.9305685903497272 0.9926064957063756 0.1473410054214868\n",
            "0.9305685903497272 0.9615875430280514 0.9926064957063756 0.26282617515146006\n",
            "0.9615875430280514 0.9770970193672135 0.9926064957063756 0.41447614130602345\n",
            "0.9770970193672135 0.9848517575367945 0.9926064957063756 0.5811694290645165\n",
            "0.9770970193672135 0.980974388452004 0.9848517575367945 0.48360321862414146\n",
            "0.980974388452004 0.9829130729943993 0.9848517575367945 0.5277841180359903\n",
            "0.9829130729943993 0.9838824152655969 0.9848517575367945 0.5531463213804572\n",
            "0.9829130729943993 0.9833977441299981 0.9838824152655969 0.5401580369900975\n",
            "0.9829130729943993 0.9831554085621987 0.9833977441299981 0.5338971726266616\n",
            "0.9829130729943993 0.983034240778299 0.9831554085621987 0.5308225142259322\n",
            "0.9829130729943993 0.9829736568863492 0.983034240778299 0.5292988255285754\n",
            "0.9829736568863492 0.9830039488323241 0.983034240778299 0.5300595419985036\n",
            "0.9829736568863492 0.9829888028593367 0.9830039488323241 0.5296789024514101\n",
            "0.9829888028593367 0.9829963758458304 0.9830039488323241 0.529869151815668\n",
            "0.9829963758458304 0.9830001623390773 0.9830039488323241 0.5299643292929693\n",
            "0.9830001623390773 0.9830020555857006 0.9830039488323241 0.5300119312399971\n",
            "0.9830001623390773 0.9830011089623889 0.9830020555857006 0.5299881291642811\n",
            "0.9830011089623889 0.9830015822740448 0.9830020555857006 0.5300000299281135\n",
            "0.9830011089623889 0.9830013456182168 0.9830015822740448 0.5299940794798556\n",
            "0.9830013456182168 0.9830014639461309 0.9830015822740448 0.5299970546855464\n",
            "0.9830014639461309 0.9830015231100878 0.9830015822740448 0.5299985423037652\n",
            "0.9830015231100878 0.9830015526920663 0.9830015822740448 0.5299992861173368\n",
            "0.9830015526920663 0.9830015674830556 0.9830015822740448 0.5299996580236923\n",
            "0.9830015674830556 0.9830015748785501 0.9830015822740448 0.5299998439758344\n",
            "0.9830015748785501 0.9830015785762974 0.9830015822740448 0.5299999369507211\n",
            "0.9830015785762974 0.983001580425171 0.9830015822740448 0.5299999834418837\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.9245223603666193e-07 1e-08 0.9830015813496079\n",
            "1e-08 0.491500795674804 0.9830015813496079 0.013804208635523878\n",
            "0.491500795674804 0.737251188512206 0.9830015813496079 0.05128296495093749\n",
            "0.737251188512206 0.8601263849309069 0.9830015813496079 0.12512799102771277\n",
            "0.8601263849309069 0.9215639831402573 0.9830015813496079 0.24442219292806314\n",
            "0.9215639831402573 0.9522827822449327 0.9830015813496079 0.40438030800572666\n",
            "0.9522827822449327 0.9676421817972702 0.9830015813496079 0.5793934479593327\n",
            "0.9522827822449327 0.9599624820211015 0.9676421817972702 0.47725504870123453\n",
            "0.9599624820211015 0.9638023319091858 0.9676421817972702 0.5236356711869179\n",
            "0.9638023319091858 0.965722256853228 0.9676421817972702 0.550168007321388\n",
            "0.9638023319091858 0.9647622943812069 0.965722256853228 0.5365897001532002\n",
            "0.9638023319091858 0.9642823131451963 0.9647622943812069 0.5300374508193603\n",
            "0.9638023319091858 0.964042322527191 0.9642823131451963 0.5268180873984583\n",
            "0.964042322527191 0.9641623178361937 0.9642823131451963 0.5284231094575844\n",
            "0.9641623178361937 0.964222315490695 0.9642823131451963 0.529229110011805\n",
            "0.964222315490695 0.9642523143179457 0.9642823131451963 0.5296329872324103\n",
            "0.9642523143179457 0.9642673137315709 0.9642823131451963 0.5298351456483199\n",
            "0.9642673137315709 0.9642748134383836 0.9642823131451963 0.5299362798788659\n",
            "0.9642748134383836 0.96427856329179 0.9642823131451963 0.5299868607590847\n",
            "0.96427856329179 0.9642804382184931 0.9642823131451963 0.5300121546415538\n",
            "0.96427856329179 0.9642795007551415 0.9642804382184931 0.5299995074146575\n",
            "0.9642795007551415 0.9642799694868173 0.9642804382184931 0.5300058309551432\n",
            "0.9642795007551415 0.9642797351209793 0.9642799694868173 0.5300026691669683\n",
            "0.9642795007551415 0.9642796179380604 0.9642797351209793 0.5300010882863302\n",
            "0.9642795007551415 0.9642795593466009 0.9642796179380604 0.5300002978469012\n",
            "0.9642795007551415 0.9642795300508712 0.9642795593466009 0.5299999026292636\n",
            "0.9642795300508712 0.964279544698736 0.9642795593466009 0.5300001002367757\n",
            "iter\n",
            "Checked val at t_min vs t_i=  3.630788283614423e-07 1e-08 0.9642795373748037\n",
            "1e-08 0.48213977368740185 0.9642795373748037 0.024851051765558477\n",
            "0.48213977368740185 0.7232096555311027 0.9642795373748037 0.08887770008058878\n",
            "0.7232096555311027 0.8437445964529532 0.9642795373748037 0.20487143007253653\n",
            "0.8437445964529532 0.9040120669138785 0.9642795373748037 0.36942733792708743\n",
            "0.9040120669138785 0.9341458021443411 0.9642795373748037 0.5540390246757049\n",
            "0.9040120669138785 0.9190789345291097 0.9341458021443411 0.4459670927190716\n",
            "0.9190789345291097 0.9266123683367253 0.9341458021443411 0.4949572361184188\n",
            "0.9266123683367253 0.9303790852405331 0.9341458021443411 0.5230506199382244\n",
            "0.9303790852405331 0.9322624436924372 0.9341458021443411 0.5381555249240209\n",
            "0.9303790852405331 0.9313207644664852 0.9322624436924372 0.5305093922629688\n",
            "0.9303790852405331 0.9308499248535091 0.9313207644664852 0.5267570215329762\n",
            "0.9308499248535091 0.9310853446599971 0.9313207644664852 0.5286274071785815\n",
            "0.9310853446599971 0.9312030545632412 0.9313207644664852 0.5295669430186015\n",
            "0.9312030545632412 0.9312619095148631 0.9313207644664852 0.5300378026110854\n",
            "0.9312030545632412 0.9312324820390521 0.9312619095148631 0.5298022816683363\n",
            "0.9312324820390521 0.9312471957769576 0.9312619095148631 0.5299200193425537\n",
            "0.9312471957769576 0.9312545526459104 0.9312619095148631 0.5299789052749391\n",
            "0.9312545526459104 0.9312582310803867 0.9312619095148631 0.5300083525185696\n",
            "0.9312545526459104 0.9312563918631486 0.9312582310803867 0.529993628539125\n",
            "0.9312563918631486 0.9312573114717677 0.9312582310803867 0.5300009904409815\n",
            "0.9312563918631486 0.9312568516674582 0.9312573114717677 0.5299973094690149\n",
            "0.9312568516674582 0.931257081569613 0.9312573114717677 0.529999149948194\n",
            "0.931257081569613 0.9312571965206904 0.9312573114717677 0.5300000701931961\n",
            "0.931257081569613 0.9312571390451516 0.9312571965206904 0.5299996100678747\n",
            "0.9312571390451516 0.931257167782921 0.9312571965206904 0.5299998401329201\n",
            "0.931257167782921 0.9312571821518056 0.9312571965206904 0.5299999551618\n",
            "0.9312571821518056 0.931257189336248 0.9312571965206904 0.530000012675021\n",
            "0.9312571821518056 0.9312571857440268 0.931257189336248 0.529999983919645\n",
            "iter\n",
            "Checked val at t_min vs t_i=  6.849928039510004e-07 1e-08 0.9312571875401374\n",
            "1e-08 0.46562859877006874 0.9312571875401374 0.043156157816505225\n",
            "0.46562859877006874 0.6984428931551031 0.9312571875401374 0.14506685796714988\n",
            "0.6984428931551031 0.8148500403476202 0.9312571875401374 0.3077095628357571\n",
            "0.8148500403476202 0.8730536139438788 0.9312571875401374 0.5023101854011758\n",
            "0.8730536139438788 0.9021554007420081 0.9312571875401374 0.6821066107521938\n",
            "0.8730536139438788 0.8876045073429435 0.9021554007420081 0.5812025193222501\n",
            "0.8730536139438788 0.8803290606434111 0.8876045073429435 0.5394734017599061\n",
            "0.8730536139438788 0.8766913372936449 0.8803290606434111 0.52036825606447\n",
            "0.8766913372936449 0.878510198968528 0.8803290606434111 0.5297844585607144\n",
            "0.878510198968528 0.8794196298059695 0.8803290606434111 0.5345941179205299\n",
            "0.878510198968528 0.8789649143872488 0.8794196298059695 0.5321806767152637\n",
            "0.878510198968528 0.8787375566778883 0.8789649143872488 0.5309804260631343\n",
            "0.878510198968528 0.8786238778232082 0.8787375566778883 0.5303819083188555\n",
            "0.878510198968528 0.8785670383958681 0.8786238778232082 0.5300830501180308\n",
            "0.878510198968528 0.8785386186821981 0.8785670383958681 0.5299337210316981\n",
            "0.8785386186821981 0.8785528285390332 0.8785670383958681 0.5300083772424373\n",
            "0.8785386186821981 0.8785457236106156 0.8785528285390332 0.5299710470561554\n",
            "0.8785457236106156 0.8785492760748244 0.8785528285390332 0.5299897116299528\n",
            "0.8785492760748244 0.8785510523069288 0.8785528285390332 0.5299990443060448\n",
            "0.8785510523069288 0.8785519404229809 0.8785528285390332 0.5300037107429382\n",
            "0.8785510523069288 0.8785514963649548 0.8785519404229809 0.5300013775175927\n",
            "0.8785510523069288 0.8785512743359418 0.8785514963649548 0.5300002109110213\n",
            "0.8785510523069288 0.8785511633214353 0.8785512743359418 0.5299996276055533\n",
            "0.8785511633214353 0.8785512188286886 0.8785512743359418 0.5299999192581599\n",
            "0.8785512188286886 0.8785512465823152 0.8785512743359418 0.5300000650796158\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.2923429845864043e-06 1e-08 0.8785512327055018\n",
            "1e-08 0.43927562135275094 0.8785512327055018 0.07128058646394542\n",
            "0.43927562135275094 0.6589134270291264 0.8785512327055018 0.21947199702719056\n",
            "0.6589134270291264 0.7687323298673141 0.8785512327055018 0.4205553383135487\n",
            "0.7687323298673141 0.823641781286408 0.8785512327055018 0.6207204528449708\n",
            "0.7687323298673141 0.7961870555768611 0.823641781286408 0.5069308256270448\n",
            "0.7961870555768611 0.8099144184316345 0.823641781286408 0.5596870101279174\n",
            "0.7961870555768611 0.8030507370042478 0.8099144184316345 0.5323780259133442\n",
            "0.7961870555768611 0.7996188962905544 0.8030507370042478 0.5194331894902272\n",
            "0.7996188962905544 0.801334816647401 0.8030507370042478 0.525848921935109\n",
            "0.801334816647401 0.8021927768258243 0.8030507370042478 0.5290991254136281\n",
            "0.8021927768258243 0.802621756915036 0.8030507370042478 0.5307349660822765\n",
            "0.8021927768258243 0.8024072668704302 0.802621756915036 0.5299161461730982\n",
            "0.8024072668704302 0.802514511892733 0.802621756915036 0.5303253308819051\n",
            "0.8024072668704302 0.8024608893815817 0.802514511892733 0.5301206822588473\n",
            "0.8024072668704302 0.802434078126006 0.8024608893815817 0.5300184001558524\n",
            "0.8024072668704302 0.8024206724982181 0.802434078126006 0.5299672696498233\n",
            "0.8024206724982181 0.8024273753121121 0.802434078126006 0.5299928340228532\n",
            "0.8024273753121121 0.802430726719059 0.802434078126006 0.5300056168659472\n",
            "0.8024273753121121 0.8024290510155856 0.802430726719059 0.529999225391949\n",
            "0.8024290510155856 0.8024298888673222 0.802430726719059 0.5300024211189243\n",
            "0.8024290510155856 0.8024294699414539 0.8024298888673222 0.5300008232482964\n",
            "0.8024290510155856 0.8024292604785197 0.8024294699414539 0.5300000243229719\n",
            "0.8024290510155856 0.8024291557470526 0.8024292604785197 0.5299996248535385\n",
            "0.8024291557470526 0.8024292081127862 0.8024292604785197 0.5299998245894374\n",
            "0.8024292081127862 0.8024292342956529 0.8024292604785197 0.529999924456191\n",
            "0.8024292342956529 0.8024292473870863 0.8024292604785197 0.5299999743871064\n",
            "iter\n",
            "Checked val at t_min vs t_i=  2.4382314941120573e-06 1e-08 0.8024292539328031\n",
            "1e-08 0.40121463196640156 0.8024292539328031 0.1106876856435451\n",
            "0.40121463196640156 0.6018219429496023 0.8024292539328031 0.30589550782423297\n",
            "0.6018219429496023 0.7021255984412027 0.8024292539328031 0.5275025039831147\n",
            "0.7021255984412027 0.7522774261870029 0.8024292539328031 0.7136907798403781\n",
            "0.7021255984412027 0.7272015123141028 0.7522774261870029 0.6114579632795478\n",
            "0.7021255984412027 0.7146635553776528 0.7272015123141028 0.5674919875569554\n",
            "0.7021255984412027 0.7083945769094278 0.7146635553776528 0.5470318318257956\n",
            "0.7021255984412027 0.7052600876753152 0.7083945769094278 0.537154484620091\n",
            "0.7021255984412027 0.703692843058259 0.7052600876753152 0.5323007657614912\n",
            "0.7021255984412027 0.7029092207497308 0.703692843058259 0.5298947570357503\n",
            "0.7029092207497308 0.703301031903995 0.703692843058259 0.5310960351977059\n",
            "0.7029092207497308 0.7031051263268628 0.703301031903995 0.5304949654059293\n",
            "0.7029092207497308 0.7030071735382968 0.7031051263268628 0.5301947536486076\n",
            "0.7029092207497308 0.7029581971440138 0.7030071735382968 0.5300447284601262\n",
            "0.7029092207497308 0.7029337089468723 0.7029581971440138 0.5299697360284532\n",
            "0.7029337089468723 0.702945953045443 0.7029581971440138 0.5300072305632858\n",
            "0.7029337089468723 0.7029398309961576 0.702945953045443 0.5299884828771887\n",
            "0.7029398309961576 0.7029428920208003 0.702945953045443 0.5299978566177266\n",
            "0.7029428920208003 0.7029444225331216 0.702945953045443 0.5300025435642599\n",
            "0.7029428920208003 0.702943657276961 0.7029444225331216 0.5300002000819604\n",
            "0.7029428920208003 0.7029432746488806 0.702943657276961 0.5299990283494388\n",
            "0.7029432746488806 0.7029434659629208 0.702943657276961 0.5299996142152892\n",
            "0.7029434659629208 0.7029435616199409 0.702943657276961 0.529999907150994\n",
            "0.7029435616199409 0.7029436094484509 0.702943657276961 0.5300000536139797\n",
            "0.7029435616199409 0.7029435855341959 0.7029436094484509 0.5299999803824803\n",
            "0.7029435855341959 0.7029435974913234 0.7029436094484509 0.5300000170019358\n",
            "iter\n",
            "Checked val at t_min vs t_i=  4.600201309112821e-06 1e-08 0.7029435915127596\n",
            "1e-08 0.35147180075637985 0.7029435915127596 0.1606627772895554\n",
            "0.35147180075637985 0.5272076961345697 0.7029435915127596 0.394849164323177\n",
            "0.5272076961345697 0.6150756438236646 0.7029435915127596 0.6184021641595089\n",
            "0.5272076961345697 0.5711416699791172 0.6150756438236646 0.49302470938363396\n",
            "0.5711416699791172 0.5931086569013909 0.6150756438236646 0.5517487640754244\n",
            "0.5711416699791172 0.582125163440254 0.5931086569013909 0.5214753075488674\n",
            "0.582125163440254 0.5876169101708224 0.5931086569013909 0.5363748675122875\n",
            "0.582125163440254 0.5848710368055382 0.5876169101708224 0.5288669974325695\n",
            "0.5848710368055382 0.5862439734881804 0.5876169101708224 0.532606262167019\n",
            "0.5848710368055382 0.5855575051468593 0.5862439734881804 0.5307329808466112\n",
            "0.5848710368055382 0.5852142709761987 0.5855575051468593 0.5297990792190514\n",
            "0.5852142709761987 0.585385888061529 0.5855575051468593 0.5302658022617939\n",
            "0.5852142709761987 0.5853000795188639 0.585385888061529 0.5300323838328661\n",
            "0.5852142709761987 0.5852571752475313 0.5853000795188639 0.5299157173026561\n",
            "0.5852571752475313 0.5852786273831976 0.5853000795188639 0.5299740470129162\n",
            "0.5852786273831976 0.5852893534510307 0.5853000795188639 0.5300032145325647\n",
            "0.5852786273831976 0.5852839904171141 0.5852893534510307 0.5299886305492407\n",
            "0.5852839904171141 0.5852866719340724 0.5852893534510307 0.5299959224865712\n",
            "0.5852866719340724 0.5852880126925515 0.5852893534510307 0.5299995684956761\n",
            "0.5852880126925515 0.5852886830717912 0.5852893534510307 0.5300013915118834\n",
            "0.5852880126925515 0.5852883478821713 0.5852886830717912 0.5300004800029112\n",
            "0.5852880126925515 0.5852881802873614 0.5852883478821713 0.5300000242490766\n",
            "0.5852880126925515 0.5852880964899565 0.5852881802873614 0.529999796373558\n",
            "0.5852880964899565 0.585288138388659 0.5852881802873614 0.5299999103100682\n",
            "0.585288138388659 0.5852881593380101 0.5852881802873614 0.5299999672795688\n",
            "iter\n",
            "Checked val at t_min vs t_i=  8.679260224361778e-06 1e-08 0.5852881698126857\n",
            "1e-08 0.2926440899063429 0.5852881698126857 0.21822806758842486\n",
            "0.2926440899063429 0.43896612985951433 0.5852881698126857 0.4780446597352002\n",
            "0.43896612985951433 0.5121271498361 0.5852881698126857 0.690687310128209\n",
            "0.43896612985951433 0.47554663984780715 0.5121271498361 0.5749114368073667\n",
            "0.43896612985951433 0.4572563848536607 0.47554663984780715 0.5243653362186557\n",
            "0.4572563848536607 0.4664015123507339 0.47554663984780715 0.5490815493952415\n",
            "0.4572563848536607 0.4618289486021973 0.4664015123507339 0.5365879694255812\n",
            "0.4572563848536607 0.459542666727929 0.4618289486021973 0.5304432375236994\n",
            "0.4572563848536607 0.45839952579079485 0.459542666727929 0.5273959888326973\n",
            "0.45839952579079485 0.45897109625936194 0.459542666727929 0.5289175317338201\n",
            "0.45897109625936194 0.45925688149364546 0.459542666727929 0.5296798633995545\n",
            "0.45925688149364546 0.45939977411078725 0.459542666727929 0.5300614200459577\n",
            "0.45925688149364546 0.45932832780221633 0.45939977411078725 0.5298706091309262\n",
            "0.45932832780221633 0.4593640509565018 0.45939977411078725 0.5299660064403255\n",
            "0.4593640509565018 0.4593819125336445 0.45939977411078725 0.530013711203119\n",
            "0.4593640509565018 0.45937298174507313 0.4593819125336445 0.5299898583123613\n",
            "0.45937298174507313 0.4593774471393588 0.4593819125336445 0.5300017846303964\n",
            "0.45937298174507313 0.45937521444221596 0.4593774471393588 0.5299958214383076\n",
            "0.45937521444221596 0.4593763307907874 0.4593774471393588 0.5299988030288647\n",
            "0.4593763307907874 0.4593768889650731 0.4593774471393588 0.5300002938251692\n",
            "0.4593763307907874 0.4593766098779303 0.4593768889650731 0.5299995484228122\n",
            "0.4593766098779303 0.4593767494215017 0.4593768889650731 0.5299999211251021\n",
            "0.4593767494215017 0.45937681919328743 0.4593768889650731 0.5300001074738689\n",
            "0.4593767494215017 0.4593767843073946 0.45937681919328743 0.5300000143007136\n",
            "0.4593767494215017 0.45937676686444817 0.4593767843073946 0.5299999677153779\n",
            "iter\n",
            "Checked val at t_min vs t_i=  1.6375400880185816e-05 1e-08 0.4593767755859214\n",
            "1e-08 0.2296883927929607 0.4593767755859214 0.27922959027300737\n",
            "0.2296883927929607 0.34453258418944105 0.4593767755859214 0.5508848515675429\n",
            "0.2296883927929607 0.28711048849120085 0.34453258418944105 0.398650737440197\n",
            "0.28711048849120085 0.31582153634032095 0.34453258418944105 0.47009968856774975\n",
            "0.31582153634032095 0.33017706026488103 0.34453258418944105 0.5092434631568322\n",
            "0.33017706026488103 0.33735482222716107 0.34453258418944105 0.5297409348549499\n",
            "0.33735482222716107 0.34094370320830103 0.34453258418944105 0.5402306559965491\n",
            "0.33735482222716107 0.33914926271773105 0.34094370320830103 0.5349654175614306\n",
            "0.33735482222716107 0.33825204247244606 0.33914926271773105 0.5323481042030995\n",
            "0.33735482222716107 0.3378034323498036 0.33825204247244606 0.5310432543190672\n",
            "0.33735482222716107 0.33757912728848233 0.3378034323498036 0.5303917786276391\n",
            "0.33735482222716107 0.3374669747578217 0.33757912728848233 0.5300662777964934\n",
            "0.33735482222716107 0.3374108984924914 0.3374669747578217 0.529903586591248\n",
            "0.3374108984924914 0.33743893662515656 0.3374669747578217 0.5299849272592639\n",
            "0.33743893662515656 0.33745295569148914 0.3374669747578217 0.530025601293215\n",
            "0.33743893662515656 0.33744594615832285 0.33745295569148914 0.5300052639678933\n",
            "0.33743893662515656 0.33744244139173973 0.33744594615832285 0.5299950955377289\n",
            "0.33744244139173973 0.3374441937750313 0.33744594615832285 0.530000179729832\n",
            "0.33744244139173973 0.3374433175833855 0.3374441937750313 0.5299976376314345\n",
            "0.3374433175833855 0.3374437556792084 0.3374441937750313 0.5299989086843724\n",
            "0.3374437556792084 0.33744397472711984 0.3374441937750313 0.5299995442092726\n",
            "0.33744397472711984 0.3374440842510756 0.3374441937750313 0.5299998619694772\n",
            "0.3374440842510756 0.3374441390130535 0.3374441937750313 0.5300000208521076\n",
            "0.3374440842510756 0.33744411163206456 0.3374441390130535 0.529999941410788\n",
            "0.33744411163206456 0.337444125322559 0.3374441390130535 0.5299999811339183\n",
            "iter\n",
            "Checked val at t_min vs t_i=  3.089613115991939e-05 1e-08 0.3374441321678062\n",
            "1e-08 0.1687220710839031 0.3374441321678062 0.3397512440231125\n",
            "0.1687220710839031 0.2530831016258547 0.3374441321678062 0.6121784034163832\n",
            "0.1687220710839031 0.2109025863548789 0.2530831016258547 0.4640900353894092\n",
            "0.2109025863548789 0.2319928439903668 0.2530831016258547 0.5348917387367693\n",
            "0.2109025863548789 0.22144771517262285 0.2319928439903668 0.4987168481623433\n",
            "0.22144771517262285 0.22672027958149482 0.2319928439903668 0.5166063709095684\n",
            "0.22672027958149482 0.2293565617859308 0.2319928439903668 0.525699009067829\n",
            "0.2293565617859308 0.23067470288814879 0.2319928439903668 0.5302827909528283\n",
            "0.2293565617859308 0.2300156323370398 0.23067470288814879 0.527987763251934\n",
            "0.2300156323370398 0.2303451676125943 0.23067470288814879 0.5291344917939192\n",
            "0.2303451676125943 0.23050993525037156 0.23067470288814879 0.5297084449076142\n",
            "0.23050993525037156 0.23059231906926017 0.23067470288814879 0.529995568795936\n",
            "0.23059231906926017 0.2306335109787045 0.23067470288814879 0.5301391675886181\n",
            "0.23059231906926017 0.23061291502398235 0.2306335109787045 0.5300673651211104\n",
            "0.23059231906926017 0.23060261704662127 0.23061291502398235 0.5300314661895298\n",
            "0.23059231906926017 0.23059746805794074 0.23060261704662127 0.5300135173020339\n",
            "0.23059231906926017 0.23059489356360047 0.23059746805794074 0.5300045430022376\n",
            "0.23059231906926017 0.23059360631643033 0.23059489356360047 0.5300000558858553\n",
            "0.23059231906926017 0.23059296269284524 0.23059360631643033 0.5299978123366611\n",
            "0.23059296269284524 0.23059328450463779 0.23059360631643033 0.5299989341142161\n",
            "0.23059328450463779 0.23059344541053406 0.23059360631643033 0.5299994949998482\n",
            "0.23059344541053406 0.2305935258634822 0.23059360631643033 0.529999775442805\n",
            "0.2305935258634822 0.23059356608995626 0.23059360631643033 0.5299999156630826\n",
            "0.23059356608995626 0.2305935862031933 0.23059360631643033 0.5299999857769375\n",
            "0.2305935862031933 0.23059359625981182 0.23059360631643033 0.5300000208326315\n",
            "iter\n",
            "Checked val at t_min vs t_i=  5.829330974109915e-05 1e-08 0.23059359123150258\n",
            "1e-08 0.11529680061575129 0.23059359123150258 0.3969833062422987\n",
            "0.11529680061575129 0.17294519592362695 0.23059359123150258 0.6627310674568062\n",
            "0.11529680061575129 0.1441209982696891 0.17294519592362695 0.5219549305085694\n",
            "0.1441209982696891 0.15853309709665803 0.17294519592362695 0.5902475074213692\n",
            "0.1441209982696891 0.15132704768317357 0.15853309709665803 0.5555928355826295\n",
            "0.1441209982696891 0.14772402297643134 0.15132704768317357 0.5386486750578013\n",
            "0.1441209982696891 0.14592251062306022 0.14772402297643134 0.5302707339714927\n",
            "0.1441209982696891 0.14502175444637466 0.14592251062306022 0.5261050940182074\n",
            "0.14502175444637466 0.14547213253471744 0.14592251062306022 0.5281859758257257\n",
            "0.14547213253471744 0.14569732157888882 0.14592251062306022 0.5292278699025209\n",
            "0.14569732157888882 0.14580991610097452 0.14592251062306022 0.5297491806347695\n",
            "0.14580991610097452 0.14586621336201738 0.14592251062306022 0.5300099269686405\n",
            "0.14580991610097452 0.14583806473149596 0.14586621336201738 0.5298795462205117\n",
            "0.14583806473149596 0.14585213904675667 0.14586621336201738 0.5299447346976226\n",
            "0.14585213904675667 0.14585917620438704 0.14586621336201738 0.5299773303604239\n",
            "0.14585917620438704 0.1458626947832022 0.14586621336201738 0.5299936285472804\n",
            "0.1458626947832022 0.14586445407260978 0.14586621336201738 0.5300017777283381\n",
            "0.1458626947832022 0.14586357442790598 0.14586445407260978 0.5299977031304036\n",
            "0.14586357442790598 0.14586401425025788 0.14586445407260978 0.5299997404275195\n",
            "0.14586401425025788 0.14586423416143385 0.14586445407260978 0.5300007590787019\n",
            "0.14586401425025788 0.14586412420584588 0.14586423416143385 0.5300002497529951\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.00010998549822734516 1e-08 0.1458640692280519\n",
            "1e-08 0.07293203961402595 0.1458640692280519 0.44937214139353265\n",
            "0.07293203961402595 0.10939805442103892 0.1458640692280519 0.7041332269242944\n",
            "0.07293203961402595 0.09116504701753243 0.10939805442103892 0.5720417321127019\n",
            "0.07293203961402595 0.08204854331577918 0.09116504701753243 0.5095849089399093\n",
            "0.08204854331577918 0.08660679516665581 0.09116504701753243 0.5405256038852791\n",
            "0.08204854331577918 0.0843276692412175 0.08660679516665581 0.5249842072737623\n",
            "0.0843276692412175 0.08546723220393665 0.08660679516665581 0.5327370321894875\n",
            "0.0843276692412175 0.08489745072257707 0.08546723220393665 0.5288561651968171\n",
            "0.08489745072257707 0.08518234146325686 0.08546723220393665 0.530795483327826\n",
            "0.08489745072257707 0.08503989609291696 0.08518234146325686 0.5298255456368088\n",
            "0.08503989609291696 0.08511111877808691 0.08518234146325686 0.5303104447998331\n",
            "0.08503989609291696 0.08507550743550193 0.08511111877808691 0.530067977799842\n",
            "0.08503989609291696 0.08505770176420945 0.08507550743550193 0.5299467573669087\n",
            "0.08505770176420945 0.08506660459985568 0.08507550743550193 0.5300073664960866\n",
            "0.08505770176420945 0.08506215318203256 0.08506660459985568 0.5299770616569012\n",
            "0.08506215318203256 0.08506437889094412 0.08506660459985568 0.5299922140059896\n",
            "0.08506437889094412 0.0850654917453999 0.08506660459985568 0.5299997902352659\n",
            "0.0850654917453999 0.08506604817262779 0.08506660459985568 0.5300035783589523\n",
            "0.0850654917453999 0.08506576995901385 0.08506604817262779 0.5300016842960458\n",
            "0.0850654917453999 0.08506563085220688 0.08506576995901385 0.5300007372641543\n",
            "0.0850654917453999 0.08506556129880338 0.08506563085220688 0.5300002637508793\n",
            "0.0850654917453999 0.08506552652210164 0.08506556129880338 0.5300000269918199\n",
            "0.0850654917453999 0.08506550913375077 0.08506552652210164 0.5299999086123027\n",
            "0.08506550913375077 0.08506551782792621 0.08506552652210164 0.5299999677995887\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.00020751712958236366 1e-08 0.08506552217501392\n",
            "1e-08 0.04253276608750696 0.08506552217501392 0.49635379410611563\n",
            "0.04253276608750696 0.06379914413126045 0.08506552217501392 0.7380743959518092\n",
            "0.04253276608750696 0.053165955109383704 0.06379914413126045 0.6149409223020967\n",
            "0.04253276608750696 0.04784936059844533 0.053165955109383704 0.5551198653677715\n",
            "0.04253276608750696 0.045191063342976144 0.04784936059844533 0.5256110202281933\n",
            "0.045191063342976144 0.04652021197071074 0.04784936059844533 0.5403331773082706\n",
            "0.045191063342976144 0.045855637656843445 0.04652021197071074 0.5329641301707263\n",
            "0.045191063342976144 0.0455233504999098 0.045855637656843445 0.5292855955937732\n",
            "0.0455233504999098 0.04568949407837662 0.045855637656843445 0.5311243663954209\n",
            "0.0455233504999098 0.04560642228914321 0.04568949407837662 0.530204857070435\n",
            "0.0455233504999098 0.04556488639452651 0.04560642228914321 0.5297451953729816\n",
            "0.04556488639452651 0.045585654341834855 0.04560642228914321 0.5299750184822344\n",
            "0.045585654341834855 0.04559603831548903 0.04560642228914321 0.5300899358404626\n",
            "0.045585654341834855 0.04559084632866194 0.04559603831548903 0.530032476678665\n",
            "0.045585654341834855 0.045588250335248395 0.04559084632866194 0.5300037474570035\n",
            "0.045585654341834855 0.045586952338541625 0.045588250335248395 0.5299893829369049\n",
            "0.045586952338541625 0.04558760133689501 0.045588250335248395 0.5299965651918652\n",
            "0.04558760133689501 0.0455879258360717 0.045588250335248395 0.5300001563200728\n",
            "0.04558760133689501 0.04558776358648335 0.0455879258360717 0.5299983607554963\n",
            "0.04558776358648335 0.045587844711277525 0.0455879258360717 0.5299992585413736\n",
            "0.045587844711277525 0.04558788527367461 0.0455879258360717 0.5299997074282221\n",
            "0.04558788527367461 0.04558790555487316 0.0455879258360717 0.5299999318778473\n",
            "0.04558790555487316 0.04558791569547243 0.0455879258360717 0.530000044096487\n",
            "0.04558790555487316 0.0455879106251728 0.04558791569547243 0.5299999879846953\n",
            "0.0455879106251728 0.04558791316032261 0.04558791569547243 0.5300000160430625\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.00039153807611384085 1e-08 0.045587911892747704\n",
            "1e-08 0.022793960946373853 0.045587911892747704 0.5379920124726214\n",
            "1e-08 0.011396985473186927 0.022793960946373853 0.3087361192846596\n",
            "0.011396985473186927 0.01709547320978039 0.022793960946373853 0.42436720785888404\n",
            "0.01709547320978039 0.019944717078077122 0.022793960946373853 0.4812749523620951\n",
            "0.019944717078077122 0.021369339012225486 0.022793960946373853 0.5096440147110844\n",
            "0.021369339012225486 0.02208164997929967 0.022793960946373853 0.5238192283227852\n",
            "0.02208164997929967 0.02243780546283676 0.022793960946373853 0.5309057594204357\n",
            "0.02208164997929967 0.022259727721068216 0.02243780546283676 0.5273625486899824\n",
            "0.022259727721068216 0.022348766591952486 0.02243780546283676 0.5291341652231991\n",
            "0.022348766591952486 0.022393286027394623 0.02243780546283676 0.5300199647988852\n",
            "0.022348766591952486 0.022371026309673553 0.022393286027394623 0.5295770656667352\n",
            "0.022371026309673553 0.02238215616853409 0.022393286027394623 0.5297985153902806\n",
            "0.02238215616853409 0.022387721097964358 0.022393286027394623 0.5299092401364267\n",
            "0.022387721097964358 0.022390503562679492 0.022393286027394623 0.5299646024811292\n",
            "0.022390503562679492 0.02239189479503706 0.022393286027394623 0.5299922836387321\n",
            "0.02239189479503706 0.022392590411215843 0.022393286027394623 0.5300061242169439\n",
            "0.02239189479503706 0.02239224260312645 0.022392590411215843 0.5299992039230463\n",
            "0.02239224260312645 0.022392416507171147 0.022392590411215843 0.5300026640737413\n",
            "0.02239224260312645 0.022392329555148797 0.022392416507171147 0.5300009340033465\n",
            "0.02239224260312645 0.022392286079137624 0.022392329555148797 0.530000068964435\n",
            "0.02239224260312645 0.022392264341132038 0.022392286079137624 0.529999636451157\n",
            "0.022392264341132038 0.02239227521013483 0.022392286079137624 0.5299998527090312\n",
            "0.02239227521013483 0.022392280644636227 0.022392286079137624 0.5299999608342617\n",
            "0.022392280644636227 0.022392283361886926 0.022392286079137624 0.5300000148993482\n",
            "0.022392280644636227 0.022392282003261578 0.022392283361886926 0.5299999878668056\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.0007387463719623573 1e-08 0.022392282682574254\n",
            "1e-08 0.011196146341287128 0.022392282682574254 0.5746817119020287\n",
            "1e-08 0.005598078170643564 0.011196146341287128 0.3465695266102982\n",
            "0.005598078170643564 0.008397112255965346 0.011196146341287128 0.4634732423783359\n",
            "0.008397112255965346 0.009796629298626236 0.011196146341287128 0.5195781611554463\n",
            "0.009796629298626236 0.010496387819956682 0.011196146341287128 0.5472369834089523\n",
            "0.009796629298626236 0.010146508559291459 0.010496387819956682 0.5334363504536328\n",
            "0.009796629298626236 0.009971568928958847 0.010146508559291459 0.5265147217766424\n",
            "0.009971568928958847 0.010059038744125153 0.010146508559291459 0.5299773677420037\n",
            "0.010059038744125153 0.010102773651708306 0.010146508559291459 0.5317073127326661\n",
            "0.010059038744125153 0.010080906197916729 0.010102773651708306 0.5308424541760095\n",
            "0.010059038744125153 0.010069972471020941 0.010080906197916729 0.5304099395103163\n",
            "0.010059038744125153 0.010064505607573047 0.010069972471020941 0.5301936607714107\n",
            "0.010059038744125153 0.0100617721758491 0.010064505607573047 0.5300855160456088\n",
            "0.010059038744125153 0.010060405459987126 0.0100617721758491 0.5300314423408524\n",
            "0.010059038744125153 0.01005972210205614 0.010060405459987126 0.5300044051556779\n",
            "0.010059038744125153 0.010059380423090646 0.01005972210205614 0.5299908864767864\n",
            "0.010059380423090646 0.010059551262573393 0.01005972210205614 0.5299976458232196\n",
            "0.010059551262573393 0.010059636682314767 0.01005972210205614 0.530001025488723\n",
            "0.010059551262573393 0.01005959397244408 0.010059636682314767 0.5299993356551728\n",
            "0.01005959397244408 0.010059615327379423 0.010059636682314767 0.5300001805770003\n",
            "0.01005959397244408 0.010059604649911753 0.010059615327379423 0.5299997581161129\n",
            "0.010059604649911753 0.010059609988645588 0.010059615327379423 0.5299999693440918\n",
            "0.010059609988645588 0.010059612658012505 0.010059615327379423 0.5300000749593132\n",
            "0.010059609988645588 0.010059611323329047 0.010059612658012505 0.5300000221517027\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.0013938557698916663 1e-08 0.010059610655987317\n",
            "1e-08 0.005029810327993658 0.010059610655987317 0.606953721425747\n",
            "1e-08 0.002514910163996829 0.005029810327993658 0.38213303890122036\n",
            "0.002514910163996829 0.003772360245995244 0.005029810327993658 0.4989049417191698\n",
            "0.003772360245995244 0.0044010852869944515 0.005029810327993658 0.5537497310034633\n",
            "0.003772360245995244 0.004086722766494848 0.0044010852869944515 0.5265578767826389\n",
            "0.004086722766494848 0.00424390402674465 0.0044010852869944515 0.5402078913320164\n",
            "0.004086722766494848 0.004165313396619749 0.00424390402674465 0.5333968230866816\n",
            "0.004086722766494848 0.004126018081557298 0.004165313396619749 0.5299808890091896\n",
            "0.004126018081557298 0.004145665739088523 0.004165313396619749 0.5316897339221107\n",
            "0.004126018081557298 0.00413584191032291 0.004145665739088523 0.5308355317861926\n",
            "0.004126018081557298 0.004130929995940104 0.00413584191032291 0.5304082655861616\n",
            "0.004126018081557298 0.0041284740387487005 0.004130929995940104 0.5301945911085628\n",
            "0.004126018081557298 0.004127246060152999 0.0041284740387487005 0.5300877435095748\n",
            "0.004126018081557298 0.004126632070855148 0.004127246060152999 0.5300343171219587\n",
            "0.004126018081557298 0.004126325076206223 0.004126632070855148 0.5300076032815538\n",
            "0.004126018081557298 0.00412617157888176 0.004126325076206223 0.5299942461931865\n",
            "0.00412617157888176 0.004126248327543991 0.004126325076206223 0.5300009247508692\n",
            "0.00412617157888176 0.004126209953212875 0.004126248327543991 0.5299975854766406\n",
            "0.004126209953212875 0.004126229140378433 0.004126248327543991 0.5299992551145961\n",
            "0.004126229140378433 0.004126238733961212 0.004126248327543991 0.5300000899329461\n",
            "0.004126229140378433 0.004126233937169823 0.004126238733961212 0.529999672523824\n",
            "0.004126233937169823 0.004126236335565517 0.004126238733961212 0.5299998812271624\n",
            "0.004126236335565517 0.004126237534763365 0.004126238733961212 0.5299999855825288\n",
            "0.004126237534763365 0.004126238134362289 0.004126238733961212 0.5300000377565027\n",
            "0.004126237534763365 0.0041262378345628264 0.004126238134362289 0.5300000116682803\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.0026299122409427964 1e-08 0.004126237684663096\n",
            "1e-08 0.002063123842331548 0.004126237684663096 0.6353632219854977\n",
            "1e-08 0.001031566921165774 0.002063123842331548 0.4152631016371768\n",
            "0.001031566921165774 0.0015473453817486608 0.002063123842331548 0.5308849793938163\n",
            "0.001031566921165774 0.0012894561514572174 0.0015473453817486608 0.4748697676338272\n",
            "0.0012894561514572174 0.0014184007666029391 0.0015473453817486608 0.503261697953602\n",
            "0.0014184007666029391 0.0014828730741758 0.0015473453817486608 0.5171629369230456\n",
            "0.0014828730741758 0.0015151092279622304 0.0015473453817486608 0.5240456240072096\n",
            "0.0015151092279622304 0.0015312273048554456 0.0015473453817486608 0.5274706307029805\n",
            "0.0015312273048554456 0.0015392863433020532 0.0015473453817486608 0.5291791266148483\n",
            "0.0015392863433020532 0.001543315862525357 0.0015473453817486608 0.53003238208002\n",
            "0.0015392863433020532 0.001541301102913705 0.001543315862525357 0.5296058367788256\n",
            "0.001541301102913705 0.001542308482719531 0.001543315862525357 0.5298191300172987\n",
            "0.001542308482719531 0.001542812172622444 0.001543315862525357 0.5299257611893482\n",
            "0.001542812172622444 0.0015430640175739005 0.001543315862525357 0.5299790729217043\n",
            "0.0015430640175739005 0.0015431899400496288 0.001543315862525357 0.530005727822267\n",
            "0.0015430640175739005 0.0015431269788117646 0.0015431899400496288 0.5299924004498645\n",
            "0.0015431269788117646 0.0015431584594306968 0.0015431899400496288 0.5299990641573902\n",
            "0.0015431584594306968 0.0015431741997401628 0.0015431899400496288 0.5300023959923733\n",
            "0.0015431584594306968 0.0015431663295854298 0.0015431741997401628 0.5300007300773788\n",
            "0.0015431584594306968 0.0015431623945080632 0.0015431663295854298 0.5299998971152265\n",
            "0.0015431623945080632 0.0015431643620467464 0.0015431663295854298 0.5300003135976171\n",
            "0.0015431623945080632 0.0015431633782774048 0.0015431643620467464 0.5300001053564418\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.004962099550410214 1e-08 0.001543162886392734\n",
            "1e-08 0.000771586443196367 0.001543162886392734 0.6604338875458655\n",
            "1e-08 0.0003857982215981835 0.000771586443196367 0.4459495733493029\n",
            "0.0003857982215981835 0.0005786923323972753 0.000771586443196367 0.5597107023744975\n",
            "0.0003857982215981835 0.0004822452769977294 0.0005786923323972753 0.5049249503110397\n",
            "0.0004822452769977294 0.0005304688046975023 0.0005786923323972753 0.5327668771694897\n",
            "0.0004822452769977294 0.0005063570408476159 0.0005304688046975023 0.5189661005269275\n",
            "0.0005063570408476159 0.0005184129227725591 0.0005304688046975023 0.5258954730806082\n",
            "0.0005184129227725591 0.0005244408637350307 0.0005304688046975023 0.5293382951313539\n",
            "0.0005244408637350307 0.0005274548342162665 0.0005304688046975023 0.5310543507886243\n",
            "0.0005244408637350307 0.0005259478489756486 0.0005274548342162665 0.530196766022051\n",
            "0.0005244408637350307 0.0005251943563553396 0.0005259478489756486 0.5297676415821898\n",
            "0.0005251943563553396 0.0005255711026654941 0.0005259478489756486 0.5299822315262867\n",
            "0.0005255711026654941 0.0005257594758205713 0.0005259478489756486 0.5300895057008508\n",
            "0.0005255711026654941 0.0005256652892430328 0.0005257594758205713 0.530035870344471\n",
            "0.0005255711026654941 0.0005256181959542635 0.0005256652892430328 0.5300090513684721\n",
            "0.0005255711026654941 0.0005255946493098788 0.0005256181959542635 0.529995641551969\n",
            "0.0005255946493098788 0.0005256064226320711 0.0005256181959542635 0.5300023464885095\n",
            "0.0005255946493098788 0.0005256005359709749 0.0005256064226320711 0.5299989940282261\n",
            "0.0005256005359709749 0.0005256034793015231 0.0005256064226320711 0.5300006702600757\n",
            "0.0005256005359709749 0.0005256020076362491 0.0005256034793015231 0.5299998321445736\n",
            "0.0005256020076362491 0.0005256027434688861 0.0005256034793015231 0.5300002511999747\n",
            "0.0005256020076362491 0.0005256023755525676 0.0005256027434688861 0.5300000416747566\n",
            "0.0005256020076362491 0.0005256021915944083 0.0005256023755525676 0.5299999369072155\n",
            "0.0005256021915944083 0.000525602283573488 0.0005256023755525676 0.5299999892897678\n",
            "0.000525602283573488 0.0005256023295630277 0.0005256023755525676 0.5300000154810106\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.00936246827761997 1e-08 0.0005256023065682578\n",
            "1e-08 0.0002628061532841289 0.0005256023065682578 0.6826353200376015\n",
            "1e-08 0.00013140807664206445 0.0002628061532841289 0.4742796821802336\n",
            "0.00013140807664206445 0.00019710711496309668 0.0002628061532841289 0.5857033834775317\n",
            "0.00013140807664206445 0.00016425759580258057 0.00019710711496309668 0.5323220824968341\n",
            "0.00013140807664206445 0.0001478328362223225 0.00016425759580258057 0.5039782355612646\n",
            "0.0001478328362223225 0.00015604521601245153 0.00016425759580258057 0.5183057004425861\n",
            "0.00015604521601245153 0.00016015140590751605 0.00016425759580258057 0.5253512514938502\n",
            "0.00016015140590751605 0.0001622045008550483 0.00016425759580258057 0.5288458270932629\n",
            "0.0001622045008550483 0.00016323104832881443 0.00016425759580258057 0.5305862229603482\n",
            "0.0001622045008550483 0.00016271777459193136 0.00016323104832881443 0.5297165947730224\n",
            "0.00016271777459193136 0.0001629744114603729 0.00016323104832881443 0.5301515509614695\n",
            "0.00016271777459193136 0.00016284609302615212 0.0001629744114603729 0.5299341084342588\n",
            "0.00016284609302615212 0.00016291025224326252 0.0001629744114603729 0.530042838584314\n",
            "0.00016284609302615212 0.00016287817263470732 0.00016291025224326252 0.5299884757291365\n",
            "0.00016287817263470732 0.00016289421243898493 0.00016291025224326252 0.5300156577122113\n",
            "0.00016287817263470732 0.0001628861925368461 0.00016289421243898493 0.5300020668607915\n",
            "0.00016287817263470732 0.00016288218258577673 0.0001628861925368461 0.5299952713296388\n",
            "0.00016288218258577673 0.00016288418756131142 0.0001628861925368461 0.5299986691064145\n",
            "0.00016288418756131142 0.00016288519004907878 0.0001628861925368461 0.5300003679845371\n",
            "0.00016288418756131142 0.00016288468880519509 0.00016288519004907878 0.5299995185472541\n",
            "0.00016288468880519509 0.00016288493942713693 0.00016288519004907878 0.5299999432647479\n",
            "0.00016288493942713693 0.00016288506473810787 0.00016288519004907878 0.5300001556259125\n",
            "0.00016288493942713693 0.00016288500208262241 0.00016288506473810787 0.5300000494478107\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.017665087977337058 1e-08 0.00016288497075487966\n",
            "1e-08 8.144748537743983e-05 0.00016288497075487966 0.7023806514400099\n",
            "1e-08 4.072874268871991e-05 8.144748537743983e-05 0.5004046364568977\n",
            "4.072874268871991e-05 6.108811403307988e-05 8.144748537743983e-05 0.6091843470181316\n",
            "4.072874268871991e-05 5.0908428360899894e-05 6.108811403307988e-05 0.5573068369828175\n",
            "4.072874268871991e-05 4.58185855248099e-05 5.0908428360899894e-05 0.5295870774725697\n",
            "4.58185855248099e-05 4.836350694285489e-05 5.0908428360899894e-05 0.5436147359320144\n",
            "4.58185855248099e-05 4.7091046233832396e-05 4.836350694285489e-05 0.5366445709957623\n",
            "4.58185855248099e-05 4.645481587932115e-05 4.7091046233832396e-05 0.5331269682291085\n",
            "4.58185855248099e-05 4.613670070206552e-05 4.645481587932115e-05 0.5313598382127895\n",
            "4.58185855248099e-05 4.597764311343771e-05 4.613670070206552e-05 0.5304741654081736\n",
            "4.58185855248099e-05 4.58981143191238e-05 4.597764311343771e-05 0.5300307987994711\n",
            "4.58185855248099e-05 4.585834992196685e-05 4.58981143191238e-05 0.5298089825370511\n",
            "4.585834992196685e-05 4.587823212054533e-05 4.58981143191238e-05 0.5299199017645055\n",
            "4.587823212054533e-05 4.5888173219834566e-05 4.58981143191238e-05 0.5299753530554377\n",
            "4.5888173219834566e-05 4.589314376947918e-05 4.58981143191238e-05 0.5300030766216287\n",
            "4.5888173219834566e-05 4.589065849465687e-05 4.589314376947918e-05 0.529989215008075\n",
            "4.589065849465687e-05 4.5891901132068025e-05 4.589314376947918e-05 0.5299961458607888\n",
            "4.5891901132068025e-05 4.58925224507736e-05 4.589314376947918e-05 0.5299996112509553\n",
            "4.58925224507736e-05 4.589283311012639e-05 4.589314376947918e-05 0.5300013439389991\n",
            "4.58925224507736e-05 4.589267778045e-05 4.589283311012639e-05 0.530000477595499\n",
            "4.58925224507736e-05 4.58926001156118e-05 4.589267778045e-05 0.5300000444233965\n",
            "4.58925224507736e-05 4.58925612831927e-05 4.58926001156118e-05 0.5299998278358277\n",
            "4.58925612831927e-05 4.589258069940225e-05 4.58926001156118e-05 0.5299999361297778\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.03333049002734483 1e-08 4.589259040750702e-05\n",
            "1e-08 2.2951295203753512e-05 4.589259040750702e-05 0.7200437990017237\n",
            "1e-08 1.1480647601876757e-05 2.2951295203753512e-05 0.5245445050370365\n",
            "1.1480647601876757e-05 1.7215971402815134e-05 2.2951295203753512e-05 0.6304818669081876\n",
            "1.1480647601876757e-05 1.4348309502345945e-05 1.7215971402815134e-05 0.5801612002765835\n",
            "1.1480647601876757e-05 1.2914478552111352e-05 1.4348309502345945e-05 0.55312510920769\n",
            "1.1480647601876757e-05 1.2197563076994054e-05 1.2914478552111352e-05 0.5390451540497954\n",
            "1.1480647601876757e-05 1.1839105339435406e-05 1.2197563076994054e-05 0.5318498641771242\n",
            "1.1480647601876757e-05 1.165987647065608e-05 1.1839105339435406e-05 0.5282112701336209\n",
            "1.165987647065608e-05 1.1749490905045743e-05 1.1839105339435406e-05 0.5300340466792539\n",
            "1.165987647065608e-05 1.1704683687850913e-05 1.1749490905045743e-05 0.5291235334572\n",
            "1.1704683687850913e-05 1.1727087296448327e-05 1.1749490905045743e-05 0.5295790081823007\n",
            "1.1727087296448327e-05 1.1738289100747036e-05 1.1749490905045743e-05 0.5298065818767708\n",
            "1.1738289100747036e-05 1.1743890002896389e-05 1.1749490905045743e-05 0.5299203278804338\n",
            "1.1743890002896389e-05 1.1746690453971065e-05 1.1749490905045743e-05 0.5299771906784848\n",
            "1.1746690453971065e-05 1.1748090679508404e-05 1.1749490905045743e-05 0.5300056195297487\n",
            "1.1746690453971065e-05 1.1747390566739734e-05 1.1748090679508404e-05 0.529991405317111\n",
            "1.1747390566739734e-05 1.1747740623124069e-05 1.1748090679508404e-05 0.5299985124790064\n",
            "1.1747740623124069e-05 1.1747915651316236e-05 1.1748090679508404e-05 0.5300020660157461\n",
            "1.1747740623124069e-05 1.1747828137220153e-05 1.1747915651316236e-05 0.5300002892482233\n",
            "1.1747740623124069e-05 1.1747784380172111e-05 1.1747828137220153e-05 0.5299994008619732\n",
            "1.1747784380172111e-05 1.1747806258696133e-05 1.1747828137220153e-05 0.5299998450572138\n",
            "1.1747806258696133e-05 1.1747817197958143e-05 1.1747828137220153e-05 0.5300000671533344\n",
            "1.1747806258696133e-05 1.1747811728327137e-05 1.1747817197958143e-05 0.5299999561059588\n",
            "1.1747811728327137e-05 1.1747814463142641e-05 1.1747817197958143e-05 0.5300000116289769\n",
            "1.1747811728327137e-05 1.174781309573489e-05 1.1747814463142641e-05 0.5299999838656705\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.06288801937019284 1e-08 1.1747813779438764e-05\n",
            "1e-08 5.878906889719382e-06 1.1747813779438764e-05 0.7360301617797934\n",
            "1e-08 2.944453444859691e-06 5.878906889719382e-06 0.5471147846566944\n",
            "1e-08 1.4772267224298455e-06 2.944453444859691e-06 0.410517333015008\n",
            "1.4772267224298455e-06 2.210840083644768e-06 2.944453444859691e-06 0.4850839464839852\n",
            "2.210840083644768e-06 2.57764676425223e-06 2.944453444859691e-06 0.5172901778093999\n",
            "2.57764676425223e-06 2.76105010455596e-06 2.944453444859691e-06 0.5324681620521002\n",
            "2.57764676425223e-06 2.669348434404095e-06 2.76105010455596e-06 0.5249491453936711\n",
            "2.669348434404095e-06 2.7151992694800276e-06 2.76105010455596e-06 0.5287256789733467\n",
            "2.7151992694800276e-06 2.738124687017994e-06 2.76105010455596e-06 0.530601120481626\n",
            "2.7151992694800276e-06 2.7266619782490108e-06 2.738124687017994e-06 0.5296644566667975\n",
            "2.7266619782490108e-06 2.732393332633502e-06 2.738124687017994e-06 0.5301330519387545\n",
            "2.7266619782490108e-06 2.7295276554412567e-06 2.732393332633502e-06 0.5298988202537546\n",
            "2.7295276554412567e-06 2.7309604940373794e-06 2.732393332633502e-06 0.5300159525653118\n",
            "2.7295276554412567e-06 2.730244074739318e-06 2.7309604940373794e-06 0.5299573905282481\n",
            "2.730244074739318e-06 2.7306022843883485e-06 2.7309604940373794e-06 0.5299866725766047\n",
            "2.7306022843883485e-06 2.730781389212864e-06 2.7309604940373794e-06 0.5300013128331285\n",
            "2.7306022843883485e-06 2.7306918368006062e-06 2.730781389212864e-06 0.5299939927692272\n",
            "2.7306918368006062e-06 2.7307366130067353e-06 2.730781389212864e-06 0.5299976528112914\n",
            "2.7307366130067353e-06 2.7307590011097996e-06 2.730781389212864e-06 0.5299994828227281\n",
            "2.7307590011097996e-06 2.7307701951613316e-06 2.730781389212864e-06 0.5300003978279005\n",
            "2.7307590011097996e-06 2.730764598135566e-06 2.7307701951613316e-06 0.5299999403243307\n",
            "2.730764598135566e-06 2.7307673966484487e-06 2.7307701951613316e-06 0.5300001690784469\n",
            "2.730764598135566e-06 2.7307659973920072e-06 2.7307673966484487e-06 0.5300000547038761\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.11865726579464464 1e-08 2.7307652977637865e-06\n",
            "1e-08 1.3703826488818932e-06 2.7307652977637865e-06 0.7510899393435507\n",
            "1e-08 6.901913244409466e-07 1.3703826488818932e-06 0.5694056680211758\n",
            "1e-08 3.500956622204733e-07 6.901913244409466e-07 0.4359850532865119\n",
            "3.500956622204733e-07 5.2014349333071e-07 6.901913244409466e-07 0.5090297008224283\n",
            "5.2014349333071e-07 6.051674088858282e-07 6.901913244409466e-07 0.540421956035757\n",
            "5.2014349333071e-07 5.62655451108269e-07 6.051674088858282e-07 0.5250623942057349\n",
            "5.62655451108269e-07 5.839114299970486e-07 6.051674088858282e-07 0.5328213548789721\n",
            "5.62655451108269e-07 5.732834405526589e-07 5.839114299970486e-07 0.5289622521194364\n",
            "5.732834405526589e-07 5.785974352748537e-07 5.839114299970486e-07 0.5308968228965035\n",
            "5.732834405526589e-07 5.759404379137563e-07 5.785974352748537e-07 0.5299308015835459\n",
            "5.759404379137563e-07 5.772689365943049e-07 5.785974352748537e-07 0.5304141270956647\n",
            "5.759404379137563e-07 5.766046872540306e-07 5.772689365943049e-07 0.5301725432084435\n",
            "5.759404379137563e-07 5.762725625838934e-07 5.766046872540306e-07 0.5300516921178056\n",
            "5.759404379137563e-07 5.761065002488248e-07 5.762725625838934e-07 0.5299912517862334\n",
            "5.761065002488248e-07 5.761895314163591e-07 5.762725625838934e-07 0.530021473193255\n",
            "5.761065002488248e-07 5.76148015832592e-07 5.761895314163591e-07 0.5300063628082837\n",
            "5.761065002488248e-07 5.761272580407084e-07 5.76148015832592e-07 0.5299988073857106\n",
            "5.761272580407084e-07 5.761376369366501e-07 5.76148015832592e-07 0.5300025851049371\n",
            "5.761272580407084e-07 5.761324474886793e-07 5.761376369366501e-07 0.5300006962375697\n",
            "5.761272580407084e-07 5.761298527646939e-07 5.761324474886793e-07 0.5299997518153168\n",
            "5.761298527646939e-07 5.761311501266866e-07 5.761324474886793e-07 0.5300002240267445\n",
            "5.761298527646939e-07 5.761305014456902e-07 5.761311501266866e-07 0.5299999879287363\n",
            "5.761305014456902e-07 5.761308257861884e-07 5.761311501266866e-07 0.5300001059676566\n",
            "5.761305014456902e-07 5.761306636159393e-07 5.761308257861884e-07 0.5300000469482012\n",
            "5.761305014456902e-07 5.761305825308147e-07 5.761306636159393e-07 0.5300000174258962\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.22388282806978158 1e-08 5.761305419882524e-07\n",
            "1e-08 2.930652709941262e-07 5.761305419882524e-07 0.7678906833148266\n",
            "1e-08 1.515326354970631e-07 2.930652709941262e-07 0.5970812677538236\n",
            "1e-08 8.076631774853156e-08 1.515326354970631e-07 0.4721556753372216\n",
            "8.076631774853156e-08 1.1614947662279733e-07 1.515326354970631e-07 0.5403620673468931\n",
            "8.076631774853156e-08 9.845789718566445e-08 1.1614947662279733e-07 0.5080933794537917\n",
            "9.845789718566445e-08 1.0730368690423089e-07 1.1614947662279733e-07 0.5246230728615082\n",
            "1.0730368690423089e-07 1.1172658176351412e-07 1.1614947662279733e-07 0.5325849817241227\n",
            "1.0730368690423089e-07 1.0951513433387251e-07 1.1172658176351412e-07 0.5286278800514965\n",
            "1.0951513433387251e-07 1.1062085804869331e-07 1.1172658176351412e-07 0.5306122972204932\n",
            "1.0951513433387251e-07 1.1006799619128291e-07 1.1062085804869331e-07 0.5296215671826767\n",
            "1.1006799619128291e-07 1.103444271199881e-07 1.1062085804869331e-07 0.530117300275669\n",
            "1.1006799619128291e-07 1.102062116556355e-07 1.103444271199881e-07 0.5298695259477336\n",
            "1.102062116556355e-07 1.102753193878118e-07 1.103444271199881e-07 0.5299934361417201\n",
            "1.102753193878118e-07 1.1030987325389995e-07 1.103444271199881e-07 0.5300553739611176\n",
            "1.102753193878118e-07 1.1029259632085588e-07 1.1030987325389995e-07 0.5300244065402601\n",
            "1.102753193878118e-07 1.1028395785433384e-07 1.1029259632085588e-07 0.5300089217020448\n",
            "1.102753193878118e-07 1.1027963862107282e-07 1.1028395785433384e-07 0.5300011790603626\n",
            "1.102753193878118e-07 1.1027747900444231e-07 1.1027963862107282e-07 0.5299973075750125\n",
            "1.1027747900444231e-07 1.1027855881275756e-07 1.1027963862107282e-07 0.5299992433730664\n",
            "1.1027855881275756e-07 1.1027909871691519e-07 1.1027963862107282e-07 0.5300002112193561\n",
            "1.1027855881275756e-07 1.1027882876483638e-07 1.1027909871691519e-07 0.5299997272965632\n",
            "1.1027882876483638e-07 1.1027896374087579e-07 1.1027909871691519e-07 0.5299999692095277\n",
            "1.1027896374087579e-07 1.102790312288955e-07 1.1027909871691519e-07 0.5300000902156998\n",
            "1.1027896374087579e-07 1.1027899748488565e-07 1.102790312288955e-07 0.5300000297101471\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.4224224553810913 1e-08 1.1027898061288072e-07\n",
            "1e-08 6.013949030644036e-08 1.1027898061288072e-07 0.7993966371271936\n",
            "1e-08 3.506974515322018e-08 6.013949030644036e-08 0.6574549141223489\n",
            "1e-08 2.253487257661009e-08 3.506974515322018e-08 0.5614518285179395\n",
            "1e-08 1.6267436288305044e-08 2.253487257661009e-08 0.5004814756429781\n",
            "1.6267436288305044e-08 1.9401154432457567e-08 2.253487257661009e-08 0.5324931110152057\n",
            "1.6267436288305044e-08 1.7834295360381305e-08 1.9401154432457567e-08 0.5169224016042011\n",
            "1.7834295360381305e-08 1.8617724896419435e-08 1.9401154432457567e-08 0.5248089201678076\n",
            "1.8617724896419435e-08 1.90094396644385e-08 1.9401154432457567e-08 0.5286754471712787\n",
            "1.90094396644385e-08 1.9205297048448032e-08 1.9401154432457567e-08 0.5305902848453286\n",
            "1.90094396644385e-08 1.9107368356443268e-08 1.9205297048448032e-08 0.5296343796857881\n",
            "1.9107368356443268e-08 1.915633270244565e-08 1.9205297048448032e-08 0.5301127088973778\n",
            "1.9107368356443268e-08 1.913185052944446e-08 1.915633270244565e-08 0.5298736389813061\n",
            "1.913185052944446e-08 1.9144091615945056e-08 1.915633270244565e-08 0.5299931972543572\n",
            "1.9144091615945056e-08 1.9150212159195353e-08 1.915633270244565e-08 0.530052958966851\n",
            "1.9144091615945056e-08 1.9147151887570205e-08 1.9150212159195353e-08 0.5300230795803366\n",
            "1.9144091615945056e-08 1.914562175175763e-08 1.9147151887570205e-08 0.5300081390543071\n",
            "1.9144091615945056e-08 1.9144856683851343e-08 1.914562175175763e-08 0.5300006685174745\n",
            "1.9144091615945056e-08 1.9144474149898198e-08 1.9144856683851343e-08 0.5299969331738004\n",
            "1.9144474149898198e-08 1.914466541687477e-08 1.9144856683851343e-08 0.5299988005815979\n",
            "1.914466541687477e-08 1.9144761050363054e-08 1.9144856683851343e-08 0.529999734550975\n",
            "1.9144761050363054e-08 1.91448088671072e-08 1.9144856683851343e-08 0.5300002012635534\n",
            "1.9144761050363054e-08 1.9144784958735127e-08 1.91448088671072e-08 0.5299999681820925\n",
            "1.9144784958735127e-08 1.9144796912921164e-08 1.91448088671072e-08 0.5300000847228459\n",
            "1.9144784958735127e-08 1.9144790935828145e-08 1.9144796912921164e-08 0.5300000261777376\n",
            "iter\n",
            "Checked val at t_min vs t_i=  0.7970256971853937 1e-08 1.9144787947281638e-08\n",
            "exi2t\n",
            "tensor([0.00000001914, 0.00000011028, 0.00000057613, 0.00000273077,\n",
            "        0.00001174781, 0.00004589259, 0.00016288497, 0.00052560231,\n",
            "        0.00154316289, 0.00412623768, 0.01005961066, 0.02239228268,\n",
            "        0.04558791189, 0.08506552218, 0.14586406923, 0.23059359123,\n",
            "        0.33744413217, 0.45937677559, 0.58528816981, 0.70294359151,\n",
            "        0.80242925393, 0.87855123271, 0.93125718754, 0.96427953737,\n",
            "        0.98300158135, 0.99260649571, 0.99706538116, 0.99893842949,\n",
            "        0.99965039424, 0.99989527322, 0.99997148541, 0.99999294757,\n",
            "        0.99999841639, 0.99999967730, 0.99999994035, 0.99999999000],\n",
            "       dtype=torch.float64)\n",
            "torch.Size([36])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "const_MSE=    torch.tensor([0.00000001914, 0.00000011028, 0.00000057613, 0.00000273077,\n",
        "        0.00001174781, 0.00004589259, 0.00016288497, 0.00052560231,\n",
        "        0.00154316289, 0.00412623768, 0.01005961066, 0.02239228268,\n",
        "        0.04558791189, 0.08506552218, 0.14586406923, 0.23059359123,\n",
        "        0.33744413217, 0.45937677559, 0.58528816981, 0.70294359151,\n",
        "        0.80242925393, 0.87855123271, 0.93125718754, 0.96427953737,\n",
        "        0.98300158135, 0.99260649571, 0.99706538116, 0.99893842949,\n",
        "        0.99965039424, 0.99989527322, 0.99997148541, 0.99999294757,\n",
        "        ], dtype=dtype, device=noise.device)\n",
        "# --- execute rr function ---\n",
        "rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, sigmas = rr_time_schedule(\n",
        "    32, const_MSE,\n",
        "    dtype,\n",
        "    noise.device\n",
        ")\n",
        "\n",
        "print(\"SIGMAS =\", sigmas)\n",
        "print(\"rrFLOW =\", rrFLOW)\n",
        "print(\"rrMSE  =\", rrMSE)\n",
        "print(\"rrML   =\", rrML)\n",
        "\n",
        "print(\"betaFLOW =\", betaFLOW)\n",
        "print(\"betaMSE  =\", betaMSE)\n",
        "print(\"betaML   =\", betaML)\n",
        "\n",
        "\n",
        "const_MSE=    torch.tensor([\n",
        "        0.00000031000, 0.00000152491,\n",
        "    ], dtype=dtype, device=noise.device)\n",
        "# --- execute rr function ---\n",
        "rrFLOW, rrMSE, rrML, betaFLOW, betaMSE, betaML, sigmas = rr_time_schedule(\n",
        "    2, const_MSE,\n",
        "    dtype,\n",
        "    noise.device\n",
        ")\n",
        "\n",
        "print(\"SIGMAS =\", sigmas)\n",
        "print(\"rrFLOW =\", rrFLOW)\n",
        "print(\"rrMSE  =\", rrMSE)\n",
        "print(\"rrML   =\", rrML)\n",
        "\n",
        "print(\"betaFLOW =\", betaFLOW)\n",
        "print(\"betaMSE  =\", betaMSE)\n",
        "print(\"betaML   =\", betaML)\n"
      ],
      "metadata": {
        "id": "tMVSSevsRoHe",
        "outputId": "04a1711c-1834-4feb-ecc3-e9ce5769f4d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tMVSSevsRoHe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIGMAS = tensor([163.79382739889, 119.23757320959,  86.80594373712,  63.19529289415,\n",
            "         46.00663020581,  33.49314255884,  24.38323918295,  17.75116665036,\n",
            "         12.92297213640,   9.40801311504,   6.84909860330,   4.98619113420,\n",
            "          3.62998163606,   2.64265174175,   1.92386874053,   1.40058974257,\n",
            "          1.01963902258,   0.74230426120,   0.54040263153,   0.39341685174,\n",
            "          0.28641018868,   0.20850859810,   0.15179570040,   0.11050831958,\n",
            "          0.08045082106,   0.05856875451,   0.04263845835,   0.03104109252,\n",
            "          0.02259812987,   0.01645159467,   0.01197687438,   0.00871924637,\n",
            "          0.00000000000], dtype=torch.float64)\n",
            "rrFLOW = tensor([0.72797354518, 0.72800830645, 0.72800651860, 0.72800723122,\n",
            "        0.72800686355, 0.72800690888, 0.72800691152, 0.72800691870,\n",
            "        0.72800691789, 0.72800691491, 0.72800691346, 0.72800691718,\n",
            "        0.72800691758, 0.72800691447, 0.72800691288, 0.72800691850,\n",
            "        0.72800691692, 0.72800691008, 0.72800691333, 0.72800691534,\n",
            "        0.72800691577, 0.72800691088, 0.72800691512, 0.72800691717,\n",
            "        0.72800692071, 0.72800691623, 0.72800691485, 0.72800691061,\n",
            "        0.72800690887, 0.72800689673, 0.72800683137, 0.00000000000],\n",
            "       dtype=torch.float64)\n",
            "rrMSE  = tensor([0.72797301081, 0.72800729842, 0.72800461664, 0.72800364265,\n",
            "        0.72800009278, 0.72799413441, 0.72798281104, 0.72796145473,\n",
            "        0.72792116837, 0.72784523710, 0.72770226793, 0.72743356188,\n",
            "        0.72693023386, 0.72599337930, 0.72426977465, 0.72116439005,\n",
            "        0.71576851169, 0.70692892830, 0.69365462279, 0.67585032606,\n",
            "        0.65479802092, 0.63273356734, 0.61183052001, 0.59348569918,\n",
            "        0.57822885988, 0.56597859396, 0.55633422942, 0.54877380371,\n",
            "        0.54274142154, 0.53758652574, 0.52999987643, 0.00000000000],\n",
            "       dtype=torch.float64)\n",
            "rrML   = tensor([0.52994548248, 0.52999609426, 0.52999349113, 0.52999452870,\n",
            "        0.52999399338, 0.52999405938, 0.52999406322, 0.52999407367,\n",
            "        0.52999407250, 0.52999406815, 0.52999406605, 0.52999407146,\n",
            "        0.52999407205, 0.52999406752, 0.52999406520, 0.52999407339,\n",
            "        0.52999407108, 0.52999406112, 0.52999406586, 0.52999406879,\n",
            "        0.52999406941, 0.52999406229, 0.52999406846, 0.52999407145,\n",
            "        0.52999407660, 0.52999407008, 0.52999406807, 0.52999406190,\n",
            "        0.52999405936, 0.52999404169, 0.52999394652, 0.00000000000],\n",
            "       dtype=torch.float64)\n",
            "betaFLOW = tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
            "betaMSE  = tensor([0.14447352323, 0.14445471611, 0.14445501414, 0.14445340645,\n",
            "        0.14445128251, 0.14444688290, 0.14443862703, 0.14442305335,\n",
            "        0.14439369340, 0.14433835797, 0.14423416306, 0.14403832425,\n",
            "        0.14367149733, 0.14298872426, 0.14173258297, 0.13946945728,\n",
            "        0.13553725497, 0.12909597658, 0.11942449460, 0.10645572542,\n",
            "        0.09112779240, 0.07507534277, 0.05988864298, 0.04659322170,\n",
            "        0.03558486892, 0.02681798619, 0.02002130087, 0.01484924155,\n",
            "        0.01096477024, 0.00807628821, 0.00597757722, 0.00000000000],\n",
            "       dtype=torch.float64)\n",
            "betaML   = tensor([81.74990259802, 59.51140402353, 43.32481003754, 31.54074018409,\n",
            "        22.96188841203, 16.71641223129, 12.16966359045,  8.85959919353,\n",
            "         6.44984951068,  4.69553506560,  3.41838199782,  2.48860572566,\n",
            "         1.81172218227,  1.31894628215,  0.96020201349,  0.69903370289,\n",
            "         0.50890137211,  0.37048371937,  0.26971470762,  0.19635417170,\n",
            "         0.14294719485,  0.10406654653,  0.07576116501,  0.05515465200,\n",
            "         0.04015296815,  0.02923163872,  0.02128083517,  0.01549259517,\n",
            "         0.01127871635,  0.00821098344,  0.00597765264,  0.00000000000],\n",
            "       dtype=torch.float64)\n",
            "SIGMAS = tensor([97.99151314225, 71.33847477844,  0.00000000000], dtype=torch.float64)\n",
            "rrFLOW = tensor([0.72800666599, 0.00000000000], dtype=torch.float64)\n",
            "rrMSE  = tensor([0.52999963564, 0.00000000000], dtype=torch.float64)\n",
            "rrML   = tensor([0.52999370573, 0.00000000000], dtype=torch.float64)\n",
            "betaFLOW = tensor([0., 0.], dtype=torch.float64)\n",
            "betaMSE  = tensor([48.90690470642,  0.00000000000], dtype=torch.float64)\n",
            "betaML   = tensor([48.90752176296,  0.00000000000], dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}